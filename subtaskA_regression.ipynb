{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using logistic regression (& other methods) to try to predict:\n",
    "* rank of the image; given sentence, compound & caption\n",
    "* idiomatic / literal; given sentence, (compound) & ChatGPT description\n",
    "\n",
    "It seems like these methods do not produce satisfactory results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import sys\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "# Code von Wiebke\n",
    "fileName = \"subtask_a_train.tsv\"\n",
    "fileDirectory = \"AdMIRe Subtask A Train/train\"\n",
    "data = pd.read_csv(fileDirectory + \"/\" + fileName, sep='\\t')\n",
    "data['expected_order'] = data['expected_order'].apply(ast.literal_eval)\n",
    "\n",
    "# descriptions given by ChatGPT for idiomatic / literal use of compound\n",
    "# read data von Julio -> csv file\n",
    "filename_desc = \"gpt-desc.csv\"\n",
    "data_desc = pd.read_csv(filename_desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ceate training data\n",
    "# X = matrix (# samples, # features) -> features = combination of embeddings for compound, sentence, caption\n",
    "# y = array (# samples)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for i in range(len(data)):\n",
    "\n",
    "    current = data.iloc[i]\n",
    "\n",
    "    # add input & place in ranking for image 1\n",
    "    sentences = [current[\"compound\"],\n",
    "                current[\"sentence\"], \n",
    "                current[\"image1_caption\"]]\n",
    "    embeddings = model.encode(sentences)\n",
    "    X.append(np.concatenate(((embeddings[0] + embeddings[1]) / 2, embeddings[2])))\n",
    "    #X.append(np.concatenate((embeddings[0], embeddings[1], embeddings[2])))\n",
    "    #X.append(embeddings) -> doesn't work\n",
    "\n",
    "    if current[\"image1_name\"] == current[\"expected_order\"][0]:\n",
    "        y.append(1)\n",
    "    elif current[\"image1_name\"] == current[\"expected_order\"][1]:\n",
    "        y.append(2)\n",
    "    elif current[\"image1_name\"] == current[\"expected_order\"][2]:\n",
    "        y.append(3)\n",
    "    elif current[\"image1_name\"] == current[\"expected_order\"][3]:\n",
    "        y.append(4)\n",
    "    else:\n",
    "        y.append(5)\n",
    "\n",
    "    # for image 2\n",
    "    sentences = [current[\"compound\"],\n",
    "                current[\"sentence\"], \n",
    "                current[\"image2_caption\"]]\n",
    "    embeddings = model.encode(sentences)\n",
    "    X.append(np.concatenate(((embeddings[0] + embeddings[1]) / 2, embeddings[2])))\n",
    "    #X.append(np.concatenate((embeddings[0], embeddings[1], embeddings[2])))\n",
    "\n",
    "    if current[\"image2_name\"] == current[\"expected_order\"][0]:\n",
    "        y.append(1)\n",
    "    elif current[\"image2_name\"] == current[\"expected_order\"][1]:\n",
    "        y.append(2)\n",
    "    elif current[\"image2_name\"] == current[\"expected_order\"][2]:\n",
    "        y.append(3)\n",
    "    elif current[\"image2_name\"] == current[\"expected_order\"][3]:\n",
    "        y.append(4)\n",
    "    else:\n",
    "        y.append(5)\n",
    "\n",
    "    # for image 3\n",
    "    sentences = [current[\"compound\"],\n",
    "                current[\"sentence\"], \n",
    "                current[\"image3_caption\"]]\n",
    "    embeddings = model.encode(sentences)\n",
    "    X.append(np.concatenate(((embeddings[0] + embeddings[1]) / 2, embeddings[2])))\n",
    "    #X.append(np.concatenate((embeddings[0], embeddings[1], embeddings[2])))\n",
    "\n",
    "    if current[\"image3_name\"] == current[\"expected_order\"][0]:\n",
    "        y.append(1)\n",
    "    elif current[\"image3_name\"] == current[\"expected_order\"][1]:\n",
    "        y.append(2)\n",
    "    elif current[\"image3_name\"] == current[\"expected_order\"][2]:\n",
    "        y.append(3)\n",
    "    elif current[\"image3_name\"] == current[\"expected_order\"][3]:\n",
    "        y.append(4)\n",
    "    else:\n",
    "        y.append(5)\n",
    "\n",
    "    # for image 4\n",
    "    sentences = [current[\"compound\"],\n",
    "                current[\"sentence\"], \n",
    "                current[\"image4_caption\"]]\n",
    "    embeddings = model.encode(sentences)\n",
    "    X.append(np.concatenate(((embeddings[0] + embeddings[1]) / 2, embeddings[2])))\n",
    "    #X.append(np.concatenate((embeddings[0], embeddings[1], embeddings[2])))\n",
    "\n",
    "    if current[\"image4_name\"] == current[\"expected_order\"][0]:\n",
    "        y.append(1)\n",
    "    elif current[\"image4_name\"] == current[\"expected_order\"][1]:\n",
    "        y.append(2)\n",
    "    elif current[\"image4_name\"] == current[\"expected_order\"][2]:\n",
    "        y.append(3)\n",
    "    elif current[\"image4_name\"] == current[\"expected_order\"][3]:\n",
    "        y.append(4)\n",
    "    else:\n",
    "        y.append(5)\n",
    "    \n",
    "    # for image 5\n",
    "    sentences = [current[\"compound\"],\n",
    "                current[\"sentence\"], \n",
    "                current[\"image5_caption\"]]\n",
    "    embeddings = model.encode(sentences)\n",
    "    X.append(np.concatenate(((embeddings[0] + embeddings[1]) / 2, embeddings[2])))\n",
    "    #X.append(np.concatenate((embeddings[0], embeddings[1], embeddings[2])))\n",
    "\n",
    "    if current[\"image5_name\"] == current[\"expected_order\"][0]:\n",
    "        y.append(1)\n",
    "    elif current[\"image5_name\"] == current[\"expected_order\"][1]:\n",
    "        y.append(2)\n",
    "    elif current[\"image5_name\"] == current[\"expected_order\"][2]:\n",
    "        y.append(3)\n",
    "    elif current[\"image5_name\"] == current[\"expected_order\"][3]:\n",
    "        y.append(4)\n",
    "    else:\n",
    "        y.append(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create version of y for determining just whether or not top1\n",
    "\n",
    "y_top1 = []\n",
    "for i in y:\n",
    "    if i == 1:\n",
    "        y_top1.append(1)\n",
    "    else:\n",
    "        y_top1.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y_top1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=4)\n",
    "\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.16      0.24      0.19        17\n",
      "           2       0.08      0.30      0.13        10\n",
      "           3       0.00      0.00      0.00        20\n",
      "           4       0.10      0.05      0.07        20\n",
      "           5       0.33      0.19      0.24        21\n",
      "\n",
      "    accuracy                           0.14        88\n",
      "   macro avg       0.13      0.16      0.13        88\n",
      "weighted avg       0.14      0.14      0.12        88\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "log_reg = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "# to see how well it fits X_train & y_train:\n",
    "# print(log_reg.score(X_train, y_train))\n",
    "\n",
    "y_pred = log_reg.predict(X_test)\n",
    "#print(y_pred)\n",
    "#print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "print(classification_report(y_test, y_pred, zero_division=0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03675762247574155"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "svm_reg = svm.SVR()\n",
    "svm_reg.fit(X_train, y_train)\n",
    "svm_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.24      0.24      0.24        17\n",
      "           2       0.07      0.20      0.10        10\n",
      "           3       0.25      0.20      0.22        20\n",
      "           4       0.33      0.30      0.32        20\n",
      "           5       0.50      0.19      0.28        21\n",
      "\n",
      "    accuracy                           0.23        88\n",
      "   macro avg       0.28      0.23      0.23        88\n",
      "weighted avg       0.31      0.23      0.25        88\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier().fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, zero_division=0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.19      0.24      0.21        17\n",
      "           2       0.19      0.30      0.23        10\n",
      "           3       0.25      0.15      0.19        20\n",
      "           4       0.32      0.30      0.31        20\n",
      "           5       0.25      0.24      0.24        21\n",
      "\n",
      "    accuracy                           0.24        88\n",
      "   macro avg       0.24      0.24      0.24        88\n",
      "weighted avg       0.25      0.24      0.24        88\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# random baseline (performs better than anything above)\n",
    "\n",
    "from random import randrange\n",
    "\n",
    "y_pred = []\n",
    "for i in range(88):\n",
    "    y_pred.append(randrange(1,6))\n",
    "\n",
    "print(classification_report(y_test, y_pred, zero_division=0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting idiomatic / literal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ceate training data\n",
    "# X = matrix (# samples, # features) -> features: combination of embeddings for compound, (sentence), literal / idiomatic description\n",
    "# y = array (# samples)\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for i in range(len(data)):\n",
    "\n",
    "    current = data.iloc[i]\n",
    "\n",
    "    # determine whether or not literal\n",
    "    #description = data_desc[(data_desc[\"compound\"]==current[\"compound\"]) \n",
    "    #                        & (data_desc[\"sentence_type\"]==\"literal\")][\"Meaning\"].item()\n",
    "    \n",
    "    # determine whether or not idiomatic\n",
    "    description = data_desc[(data_desc[\"compound\"]==current[\"compound\"]) \n",
    "                            & (data_desc[\"sentence_type\"]==\"idiomatic\")][\"Meaning\"].item()\n",
    "    \n",
    "    sentences = [current[\"compound\"],\n",
    "                current[\"sentence\"], \n",
    "                description]\n",
    "    \n",
    "    embeddings = model.encode(sentences)\n",
    "\n",
    "    X.append(np.concatenate(((embeddings[0] + embeddings[1]) / 2, embeddings[2])))\n",
    "    #X.append(np.concatenate((embeddings[1], embeddings[2])))\n",
    "\n",
    "    if current[\"sentence_type\"] == \"literal\":\n",
    "        y.append(1)\n",
    "    else:\n",
    "        y.append(0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      1.00      0.77        10\n",
      "           1       1.00      0.25      0.40         8\n",
      "\n",
      "    accuracy                           0.67        18\n",
      "   macro avg       0.81      0.62      0.58        18\n",
      "weighted avg       0.79      0.67      0.61        18\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_reg = LogisticRegression().fit(X_train, y_train)\n",
    "y_pred = log_reg.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, zero_division=0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.90      0.69        10\n",
      "           1       0.50      0.12      0.20         8\n",
      "\n",
      "    accuracy                           0.56        18\n",
      "   macro avg       0.53      0.51      0.45        18\n",
      "weighted avg       0.53      0.56      0.47        18\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier().fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, zero_division=0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07521790391705974"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_reg = svm.SVR().fit(X_train, y_train)\n",
    "svm_reg.score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
