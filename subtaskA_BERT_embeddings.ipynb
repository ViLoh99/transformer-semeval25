{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read tsv file\n",
    "import csv\n",
    "import sys\n",
    "import ast\n",
    "\n",
    "# file name: subtask_a_sample.tsv\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "dataA_train = pd.read_csv(\"subtask_a_train.tsv\", sep='\\t')\n",
    "dataA_train['expected_order'] = dataA_train['expected_order'].apply(ast.literal_eval)\n",
    "dataA_dev = pd.read_csv(\"subtask_a_dev.tsv\", sep='\\t')\n",
    "dataA_test = pd.read_csv(\"subtask_a_test.tsv\", sep='\\t')\n",
    "\n",
    "dataA = pd.concat([dataA_train,dataA_dev,dataA_test])\n",
    "# reset index\n",
    "dataA = dataA.reset_index(drop=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def only_train(dataA):\n",
    "    return pd.concat([dataA[dataA[\"subset\"] == \"Sample\"],dataA[dataA[\"subset\"]== \"Train\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT model \n",
    "\n",
    "### without fine-tuning, classification of idiomatic/literal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idea: we use a pretrained BERT model to generate embeddings of sentences and of the compound in the context of the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# model is selected from https://huggingface.co/models\n",
    "checkpoint = 'bert-base-uncased' #\"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "tokenizer.model_max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(batch):\n",
    "    return tokenizer(batch, padding=True, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 2009, 2165, 1037, 2843, 1997, 8999, 21956, 2000, 2131, 1996, 2214, 3194, 2770, 2153, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "It took a lot of elbow grease to get the old engine running again.\n",
      "\n",
      "[101, 2009, 1005, 1055, 1037, 5377, 2645, 2005, 2149, 1010, 2004, 2002, 2003, 1037, 2851, 2711, 1998, 1045, 2572, 1037, 2305, 13547, 1010, 2061, 1045, 2424, 2008, 2183, 2000, 3637, 2012, 1023, 1012, 2382, 2428, 7659, 2041, 1996, 2190, 2847, 1012, 102]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "It's a constant battle for us, as he is a morning person and I am a night owl, so I find that going to sleep at 9.30 really cuts out the best hours.\n",
      "\n",
      "[101, 2130, 1996, 5399, 6534, 2100, 3478, 2797, 3239, 2038, 1037, 2540, 1997, 2751, 1006, 1998, 1037, 2919, 13606, 27983, 1007, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Even the somewhat seedy failed private eye has a heart of gold (and a bad hairstyle).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "demonstrate = tokenize(dataA[\"sentence\"][:3].tolist())\n",
    "for i in range(3):\n",
    "    print(demonstrate[\"input_ids\"][i])  \n",
    "    print(demonstrate[\"attention_mask\"][i])\n",
    "    print(dataA[\"sentence\"][i])\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"sentence\"-column is tokenized and passed to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[101, 8999, 21956, 102, 0, 0],\n",
       " [101, 2305, 13547, 102, 0, 0],\n",
       " [101, 2540, 1997, 2751, 102, 0]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenize all sentences\n",
    "dataA_sentence_tokenized = tokenize(dataA[\"sentence\"].tolist())\n",
    "dataA_compound_tokenized = tokenize(dataA[\"compound\"].tolist())\n",
    "\n",
    "print(len(dataA_compound_tokenized[\"input_ids\"][0]), len(dataA_sentence_tokenized[\"input_ids\"][0]))\n",
    "dataA_compound_tokenized[\"input_ids\"][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModel\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = AutoModel.from_pretrained(checkpoint, output_hidden_states=True).to(device)\n",
    "model = model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert input_ids to tensor\n",
    "input_ids_sentence = torch.tensor(dataA_sentence_tokenized[\"input_ids\"]).to(device)\n",
    "attention_mask_sentence = torch.tensor(dataA_sentence_tokenized[\"attention_mask\"]).to(device)\n",
    "\n",
    "# pass input_ids to model\n",
    "with torch.no_grad():\n",
    "    output = model(input_ids_sentence, attention_mask_sentence)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of items, number of \n",
    "output.last_hidden_state.shape\n",
    "# number of items, length of input_ids ,number of hidden units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_states_sentence = output.hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Number of layers:\", len(hidden_states_sentence), \"  (including initial embeddings)\")\n",
    "layer_i = 0\n",
    "\n",
    "print (\"Number of batches:\", len(hidden_states_sentence[layer_i]))\n",
    "batch_i = 0\n",
    "\n",
    "print (\"Number of tokens:\", len(hidden_states_sentence[layer_i][batch_i]))\n",
    "token_i = 0\n",
    "\n",
    "print (\"Number of hidden units:\", len(hidden_states_sentence[layer_i][batch_i][token_i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# different pooling methods for embeddings are computed\n",
    "# NOTE: padding tokens should be excluded (not done yet)\n",
    "\n",
    "def get_sentence_embedding(hidden_states,method):\n",
    "    sentence_embedding = []\n",
    "    if method == 'meanLast4': # average of all tokens of the last 4 layers\n",
    "        for i in range(len(hidden_states[0])):\n",
    "            # token_vecs is mean of last 4 layers\n",
    "            token_tensor = torch.stack([hidden_states[-1][i], hidden_states[-2][i], hidden_states[-3][i], hidden_states[-4][i]], dim=0)\n",
    "            token_vecs = torch.mean(token_tensor, dim=0)\n",
    "            sentence_embedding.append(torch.mean(token_vecs, dim=0))\n",
    "    elif method == 'meanSecondToLast': # average of second to last layer\n",
    "        for i in range(len(hidden_states[-2])):\n",
    "            token_vecs = hidden_states[-2][i]\n",
    "            sentence_embedding.append(torch.mean(token_vecs, dim=0))\n",
    "    elif method == 'meanLast': # average of last layer\n",
    "        for i in range(len(hidden_states[-1])):\n",
    "            token_vecs = hidden_states[-1][i]\n",
    "            sentence_embedding.append(torch.mean(token_vecs, dim=0))\n",
    "    elif method == 'lastCLS': # CLS token of last layer\n",
    "        sentence_embedding = hidden_states[-1][:, 0, :]\n",
    "    elif method == 'meanFirst': # average of first layer\n",
    "        for i in range(len(hidden_states[0])):\n",
    "            token_vecs = hidden_states[0][i]\n",
    "            sentence_embedding.append(torch.mean(token_vecs, dim=0))\n",
    "    elif method == 'firstCLS': # CLS token of first layer\n",
    "        sentence_embedding = hidden_states[0][:, 0, :]\n",
    "    return sentence_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use all methods for getting sentence embeddings and add them to dataA\n",
    "\n",
    "methods = ['meanSecondToLast','meanLast4','meanLast','meanFirst','firstCLS','lastCLS']\n",
    "\n",
    "for method in methods:\n",
    "    X = get_sentence_embedding(hidden_states_sentence,method)\n",
    "    X = np.array([x.cpu().numpy() for x in X]).tolist()\n",
    "    # add a new column to dataA \n",
    "    dataA['sentence_embedding_'+ method] = X\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Ergebnisse sind erstaunlich gut. Allerdings sind sie auch sehr abh√§ngig von random_state (teste 0,10,13,42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "# mlp\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "# evaluation\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "for method in methods: \n",
    "    # get data for training (subset column has value train or sample)\n",
    "    dataA_train = only_train(dataA)\n",
    "\n",
    "    X = dataA_train['sentence_embedding_'+ method].tolist()\n",
    "    y = dataA_train[\"sentence_type\"]\n",
    "\n",
    "    # split in train and test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "    print('=========================================================')\n",
    "    print(method)\n",
    "    # logistic regression\n",
    "#    clf = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "#    clf = RandomForestClassifier(max_depth=2, random_state=0).fit(X_train, y_train)\n",
    "    clf = SVC(kernel='linear').fit(X_train, y_train)\n",
    "#    clf = MLPClassifier(random_state=0, max_iter=300).fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "    #classification report\n",
    "    print(classification_report(y_test, y_pred,zero_division=0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy classifier most frequent\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "\n",
    "# dummy classifier most frequent\n",
    "clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"dummy classifier most frequent\")\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "#classification report\n",
    "print(classification_report(y_test, y_pred,zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataA.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare compound embeddings in sentence and in chatGPT definitions.\n",
    "#### 1) get contextualized compound embeddings for compounds in sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "##!pip install inflect\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sometimes the compound occurs in plural form in the sentence\n",
    "\n",
    "# add a new column to dataA with the plural form of the compound \n",
    "\n",
    "\n",
    "from re import *\n",
    "import inflect\n",
    "\n",
    "engine = inflect.engine()\n",
    "\n",
    "dataA[\"compound_plural\"] = [None for i in range(len(dataA))]\n",
    "\n",
    "for i in range(len(dataA[\"compound\"])):\n",
    "    dataA[\"compound_plural\"][i] = engine.plural(dataA[\"compound\"][i])\n",
    "\n",
    "dataA_compound_plural_tokenized = tokenize(dataA[\"compound_plural\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = inflect.engine()\n",
    "t = engine.plural(\"color in the grass\")\n",
    "tt = engine.plural(t)\n",
    "t, tt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataA[\"compound_plural\"][70:].value_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes the compound occurs in the sentence only in plural form. So both forms are needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.tokenize(\"rotten apples and oranges are in the woodbasket\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns the index of the compound in the sentence\n",
    "def get_idx(compound_tokens, compound_plural_tokens, sentence_tokens):\n",
    "    # remove 0-tokens from compound_tokens (removes tokens that are due to padding)\n",
    "    compound_tokens = [i for i in compound_tokens if i != 0]\n",
    "    # remove [CLS] and [SEP] from compound_tokens\n",
    "    compound_tokens = compound_tokens[1:-1]\n",
    "    compound_plural_tokens = [i for i in compound_plural_tokens if i != 0]\n",
    "    compound_plural_tokens = compound_plural_tokens[1:-1]\n",
    "    idx = []\n",
    "    # find the first occurence of the sequence of compound_tokens in sentence_tokens (singular and plural forms)\n",
    "    for i in range(len(sentence_tokens)):\n",
    "        if sentence_tokens[i:i+len(compound_tokens)] == compound_tokens:\n",
    "            for j in range(i, i+ len(compound_tokens)):\n",
    "                idx.append(j)\n",
    "    for i in range(len(sentence_tokens)):\n",
    "        if sentence_tokens[i:i+len(compound_plural_tokens)] == compound_plural_tokens:\n",
    "            for j in range(i, i+ len(compound_plural_tokens)):\n",
    "                idx.append(j)\n",
    "    # remove duplicates from idx\n",
    "    idx = list(set(idx))\n",
    "    return idx\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testen\n",
    "get_idx([99,1,5,100,0,0],[99,1,5,2,100,0,0],[1,5,3,7,4,1,5,2,1,9,0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_states_sentence[-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns the embeddings of the tokens in idxList. \n",
    "# The embeddings are combined to a single embedding by different averaging methods\n",
    "import numpy as np\n",
    "def get_idxList_embedding(hidden_states,idxLists,method):\n",
    "    embedding = []\n",
    "    if method == 'meanLast4':\n",
    "        for i in range(len(hidden_states[-1])):\n",
    "            # token_vecs is mean of last 4 layers\n",
    "            idxList = idxLists[i]\n",
    "            token_tensor = torch.stack([hidden_states[-1][i][idxList], hidden_states[-2][i][idxList], hidden_states[-3][i][idxList], hidden_states[-4][i][idxList]], dim=0)\n",
    "            token_vecs = torch.mean(token_tensor, dim=0)\n",
    "            embedding.append(torch.mean(token_vecs, dim=0).tolist())\n",
    "    elif method == 'meanSecondToLast':\n",
    "        for i in range(len(hidden_states[-2])):\n",
    "            idxList = idxLists[i]\n",
    "            token_vecs = hidden_states[-2][i][idxList]\n",
    "            embedding.append(torch.mean(token_vecs, dim=0).tolist())\n",
    "    elif method == 'meanLast':\n",
    "        for i in range(len(hidden_states[-1])):\n",
    "            idxList = idxLists[i]\n",
    "            token_vecs = hidden_states[-1][i][idxList]\n",
    "            embedding.append(torch.mean(token_vecs, dim=0).tolist())\n",
    "    elif method == 'meanFirst':\n",
    "        for i in range(len(hidden_states[0])):\n",
    "            idxList = idxLists[i]\n",
    "            token_vecs = hidden_states[0][i][idxList]\n",
    "            embedding.append(torch.mean(token_vecs, dim=0).tolist())\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add column to dataA with the indices of the compound in the sentence\n",
    "dataA[\"compound_idx\"] = [get_idx(dataA_compound_tokenized[\"input_ids\"][i], dataA_compound_plural_tokenized[\"input_ids\"][i], dataA_sentence_tokenized[\"input_ids\"][i]) for i in range(len(dataA))]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print dataA[\"sentence\"] if compound_idx is empty (ideally there should be no empty compound_idx)\n",
    "for i in range(len(dataA)):\n",
    "    if len(dataA[\"compound_idx\"][i]) == 0:\n",
    "        print(dataA[\"compound\"][i])\n",
    "        print(dataA[\"sentence\"][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# add column compound_embedding to dataA use method 'meanLast'\n",
    "compound_methods = ['meanSecondToLast','meanLast4','meanLast','meanFirst']\n",
    "for method in compound_methods:\n",
    "    dataA['compound_embedding_'+ method] = get_idxList_embedding(hidden_states_sentence,dataA[\"compound_idx\"],method) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataA.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compound_embedding_ enth√§lt die Embedding des Compounds im Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataA_train = only_train(dataA)\n",
    "\n",
    "\n",
    "for method in compound_methods:\n",
    "    X = dataA_train['compound_embedding_'+ method].tolist()\n",
    "    y = dataA_train[\"sentence_type\"]\n",
    "\n",
    "    # split in train and test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "    print('=========================================================')\n",
    "    print(method)\n",
    "    # logistic regression\n",
    "    clf = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "    #classification report\n",
    "    print(classification_report(y_test, y_pred,zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Get contextualized compound embeddings in gpt_sentences and gpt_meaning and gpt_pic embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read chatGPT data from csv\n",
    "\n",
    "data_chatGPT_train = pd.read_csv(\"chatGPTNew_train.csv\")\n",
    "data_chatGPT_dev = pd.read_csv(\"chatGPTNew_dev.csv\")\n",
    "data_chatGPT_test = pd.read_csv(\"chatGPTNew_test.csv\")\n",
    "data_chatGPT = pd.concat([data_chatGPT_train,data_chatGPT_dev,data_chatGPT_test])\n",
    "\n",
    "data_chatGPT = data_chatGPT.reset_index(drop=True)\n",
    "\n",
    "\n",
    "# rename each column with \"gpt_\" in front of the column name\n",
    "data_chatGPT.rename(columns=lambda x: 'gpt_' + x, inplace=True)\n",
    "data_chatGPT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_chatGPT.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_chatGPT[\"gpt_idiomatic_meaning\"][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_chatGPT[\"compound\"] = [None for i in range(len(data_chatGPT))]\n",
    "for i in range(len(data_chatGPT)):\n",
    "    data_chatGPT[\"compound\"][i] = data_chatGPT[\"gpt_idiomatic_meaning\"][i].split(\" is\")[0].strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpt data needs some cleanup:\n",
    "\n",
    "# replace ‚Äô with ' in all columns\n",
    "for column in data_chatGPT.columns:\n",
    "    data_chatGPT[column] = data_chatGPT[column].str.replace(\"‚Äô\",\"'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine dataA and data_chatGPT\n",
    "# \n",
    "merged_df = pd.merge(dataA, data_chatGPT, on='compound')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.shape, data_chatGPT.shape, dataA.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataA = merged_df\n",
    "dataA.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentence embeddings \n",
    "\n",
    "types = [\"literal_sentence\",\"idiomatic_sentence\",\"literal_meaning\",\"idiomatic_meaning\"]\n",
    "\n",
    "compound_tokenized = tokenize(dataA[\"compound\"].tolist())\n",
    "compound_plural_tokenized = tokenize(dataA[\"compound_plural\"].tolist())    \n",
    "\n",
    "for t in types:\n",
    "    # tokenize the column\n",
    "    tokenized = tokenize(dataA[\"gpt_\"+t].tolist())\n",
    "\n",
    "    # hidden states for gpt_Meaning\n",
    "    input_ids = torch.tensor(tokenized[\"input_ids\"]).to(device)\n",
    "    attention_mask = torch.tensor(tokenized[\"attention_mask\"]).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids, attention_mask)\n",
    "\n",
    "    hidden_states = output.hidden_states\n",
    "\n",
    "    # add a columns to data_chatGPT with the embeddings of the gpt_sentence for each method in methods\n",
    "    for method in methods:\n",
    "        X = get_sentence_embedding(hidden_states,method)\n",
    "        X = np.array([x.cpu().numpy() for x in X]).tolist()\n",
    "        dataA[\"gpt_\"+ t + \"_embedding_\"+ method] = X\n",
    "    # add gpt_compound_embeddings\n",
    "\n",
    "    # identify the indices of the compound in the sentence and use it to get the embeddings of the compound\n",
    "    dataA[\"gpt_compound_idx_\"+t] = [get_idx(compound_tokenized[\"input_ids\"][i], compound_plural_tokenized[\"input_ids\"][i], tokenized[\"input_ids\"][i]) for i in range(len(dataA))]\n",
    "    # apply the methods in compound_methods to get the embeddings of the compound\n",
    "    for method in compound_methods:\n",
    "        dataA['gpt_compound_embedding_'+ t + \"_\"+ method] = get_idxList_embedding(hidden_states,dataA[\"gpt_compound_idx_\" + t],method) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataA['gpt_compound_embedding_literal_sentence_meanLast'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) ### Use cosine similarity between compound_embedding in sentence and in gpt sentence/meaning to decide idiomatic/literal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(u, v):\n",
    "    return np.dot(u, v) / (np.linalg.norm(u) * np.linalg.norm(v))\n",
    "\n",
    "\n",
    "def compare(emb,emb0,emb1):\n",
    "    sim0 = cosine_similarity(emb,emb0)\n",
    "    sim1 = cosine_similarity(emb,emb1)\n",
    "    if sim0 > sim1:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataA.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in [\"sentence\", \"meaning\"]:\n",
    "    m = \"meanLast4\"\n",
    "\n",
    "    gpt_compound_embedding_idiomatic = dataA[\"gpt_compound_embedding_\" + \"idiomatic_\" + t + \"_\" + m]\n",
    "    gpt_compound_embedding_literal = dataA[\"gpt_compound_embedding_\" + \"literal_\" + t + \"_\" + m]\n",
    "\n",
    "    preds = []\n",
    "    for i in range(len(dataA)):\n",
    "        idx = compare(dataA[\"compound_embedding_\" + m][i],gpt_compound_embedding_literal[i],gpt_compound_embedding_idiomatic[i])\n",
    "        preds.append([\"literal\",\"idiomatic\"][idx])\n",
    "\n",
    "    dataA[\"pred_compound_sentence_and_compound_\" + t] = preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataA[\"pred_compound_sentence_and_compound_sentence\"].value_counts(), dataA[\"pred_compound_sentence_and_compound_meaning\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataA_train = only_train(dataA)\n",
    "\n",
    "# check accuracy of the predictions: idiomaticity predicted by compound embedding in sentence compared to \n",
    "# compound embedding in gpt_sentence \n",
    "y = dataA_train[\"sentence_type\"]\n",
    "y_pred = dataA_train[\"pred_compound_sentence_and_compound_sentence\"]\n",
    "print(\"compound sentence\")\n",
    "print(accuracy_score(y, y_pred))\n",
    "print(classification_report(y, y_pred,zero_division=0))\n",
    "\n",
    "y_pred = dataA_train[\"pred_compound_sentence_and_compound_meaning\"]\n",
    "print(\"compound meaning\")\n",
    "print(accuracy_score(y, y_pred))\n",
    "print(classification_report(y, y_pred,zero_division=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine similarity between sentences and gpt sentences/meanings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in [\"sentence\", \"meaning\"]:\n",
    "    for m in [\"lastCLS\", \"meanLast4\"]: \n",
    "\n",
    "        gpt_embedding_idiomatic = dataA[\"gpt_idiomatic_\" + t + \"_embedding_\" + m]\n",
    "        gpt_embedding_literal = dataA[\"gpt_literal_\" + t + \"_embedding_\" + m]\n",
    "\n",
    "        preds = []\n",
    "        for i in range(len(dataA)):\n",
    "            idx = compare(dataA[\"sentence_embedding_\" + m][i],gpt_embedding_literal[i],gpt_embedding_idiomatic[i])\n",
    "            preds.append([\"literal\",\"idiomatic\"][idx])\n",
    "\n",
    "        dataA[\"pred_sentence_and_\" + t + \"_\" + m] = preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataA_train = only_train(dataA)\n",
    "\n",
    "for m in  [\"lastCLS\", \"meanLast4\"]:\n",
    "    # check accuracy of the predictions: idiomaticity predicted by sentence embedding compared to \n",
    "    # gpt embedding \n",
    "    y = dataA_train[\"sentence_type\"]\n",
    "    y_pred = dataA_train[\"pred_sentence_and_sentence_\" + m]\n",
    "    print(m)\n",
    "    print(\"sentence\")\n",
    "    print(accuracy_score(y, y_pred))\n",
    "    print(classification_report(y, y_pred,zero_division=0))\n",
    "    print(\"-----------------\")\n",
    "\n",
    "    y_pred = dataA_train[\"pred_sentence_and_meaning_\" + m]\n",
    "    print(\"meaning\")\n",
    "    print(accuracy_score(y, y_pred))\n",
    "    print(classification_report(y, y_pred,zero_division=0))\n",
    "    print(\"==========================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting images by cosine similarity of embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize captions\n",
    "dataA_image1_caption_tokenized = tokenize(dataA[\"image1_caption\"].tolist())\n",
    "dataA_image2_caption_tokenized = tokenize(dataA[\"image2_caption\"].tolist())\n",
    "dataA_image3_caption_tokenized = tokenize(dataA[\"image3_caption\"].tolist())\n",
    "dataA_image4_caption_tokenized = tokenize(dataA[\"image4_caption\"].tolist())\n",
    "dataA_image5_caption_tokenized = tokenize(dataA[\"image5_caption\"].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataA[\"image1_caption\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get embeddings of images\n",
    "methods = ['meanLast4','lastCLS']\n",
    "\n",
    "# hidden states for image1_caption\n",
    "input_ids = torch.tensor(dataA_image1_caption_tokenized[\"input_ids\"]).to(device)\n",
    "attention_mask = torch.tensor(dataA_image1_caption_tokenized[\"attention_mask\"]).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(input_ids, attention_mask)\n",
    "\n",
    "hidden_states_gpt_image1 = output.hidden_states\n",
    "\n",
    "# add a columns to dataA with the embeddings of the image1_caption for each method in methods\n",
    "for method in methods:\n",
    "    X = get_sentence_embedding(hidden_states_gpt_image1,method)\n",
    "    X = np.array([x.cpu().numpy() for x in X]).tolist()\n",
    "    dataA['image1_caption_embedding_'+ method] = X\n",
    "\n",
    "# hidden states for image2_caption\n",
    "input_ids = torch.tensor(dataA_image2_caption_tokenized[\"input_ids\"]).to(device)\n",
    "attention_mask = torch.tensor(dataA_image2_caption_tokenized[\"attention_mask\"]).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(input_ids, attention_mask)\n",
    "\n",
    "hidden_states_gpt_image2 = output.hidden_states\n",
    "\n",
    "# add a columns to dataA with the embeddings of the image2_caption for each method in methods\n",
    "for method in methods:\n",
    "    X = get_sentence_embedding(hidden_states_gpt_image2,method)\n",
    "    X = np.array([x.cpu().numpy() for x in X]).tolist()\n",
    "    dataA['image2_caption_embedding_'+ method] = X\n",
    "\n",
    "# hidden states for image3_caption\n",
    "input_ids = torch.tensor(dataA_image3_caption_tokenized[\"input_ids\"]).to(device)\n",
    "attention_mask = torch.tensor(dataA_image3_caption_tokenized[\"attention_mask\"]).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(input_ids, attention_mask)\n",
    "\n",
    "hidden_states_gpt_image3 = output.hidden_states\n",
    "\n",
    "# add a columns to dataA with the embeddings of the image3_caption for each method in methods\n",
    "\n",
    "for method in methods:\n",
    "    X = get_sentence_embedding(hidden_states_gpt_image3,method)\n",
    "    X = np.array([x.cpu().numpy() for x in X]).tolist()\n",
    "    dataA['image3_caption_embedding_'+ method] = X\n",
    "\n",
    "# hidden states for image4_caption\n",
    "input_ids = torch.tensor(dataA_image4_caption_tokenized[\"input_ids\"]).to(device)\n",
    "attention_mask = torch.tensor(dataA_image4_caption_tokenized[\"attention_mask\"]).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(input_ids, attention_mask)\n",
    "\n",
    "hidden_states_gpt_image4 = output.hidden_states\n",
    "\n",
    "# add a columns to dataA with the embeddings of the image4_caption for each method in methods\n",
    "for method in methods:\n",
    "    X = get_sentence_embedding(hidden_states_gpt_image4,method)\n",
    "    X = np.array([x.cpu().numpy() for x in X]).tolist()\n",
    "    dataA['image4_caption_embedding_'+ method] = X\n",
    "\n",
    "# hidden states for image5_caption\n",
    "input_ids = torch.tensor(dataA_image5_caption_tokenized[\"input_ids\"]).to(device)\n",
    "attention_mask = torch.tensor(dataA_image5_caption_tokenized[\"attention_mask\"]).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(input_ids, attention_mask)\n",
    "\n",
    "hidden_states_gpt_image5 = output.hidden_states\n",
    "\n",
    "# add a columns to dataA with the embeddings of the image5_caption for each method in methods\n",
    "for method in methods:\n",
    "    X = get_sentence_embedding(hidden_states_gpt_image5,method)\n",
    "    X = np.array([x.cpu().numpy() for x in X]).tolist()\n",
    "    dataA['image5_caption_embedding_'+ method] = X\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataA.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_rankings = []\n",
    "for i in range(len(dataA)):\n",
    "    # compare cosine similarity of each picture_caption_embedding_meanLast4 and compound_embedding_meanLast4\n",
    "    compound_embedding = dataA['compound_embedding_meanLast4'][i]\n",
    "    image1_caption_embedding = dataA['image1_caption_embedding_meanLast4'][i]\n",
    "    image2_caption_embedding = dataA['image2_caption_embedding_meanLast4'][i]\n",
    "    image3_caption_embedding = dataA['image3_caption_embedding_meanLast4'][i]\n",
    "    image4_caption_embedding = dataA['image4_caption_embedding_meanLast4'][i]\n",
    "    image5_caption_embedding = dataA['image5_caption_embedding_meanLast4'][i]\n",
    "    similarity1 = cosine_similarity(compound_embedding,image1_caption_embedding)\n",
    "    similarity2 = cosine_similarity(compound_embedding,image2_caption_embedding)\n",
    "    similarity3 = cosine_similarity(compound_embedding,image3_caption_embedding)\n",
    "    similarity4 = cosine_similarity(compound_embedding,image4_caption_embedding)\n",
    "    similarity5 = cosine_similarity(compound_embedding,image5_caption_embedding)\n",
    "    # sort the similarities\n",
    "    similarities = [similarity1,similarity2,similarity3,similarity4,similarity5]\n",
    "    # sort and give indices\n",
    "    idx = np.argsort(similarities)\n",
    "    # reverse the indices\n",
    "    idx = idx[::-1]\n",
    "    pred_rankings.append(idx)\n",
    "dataA['pred_rankings'] = pred_rankings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities, idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataA[\"pred_rankings\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(dataA)):\n",
    "    idxs = dataA['pred_rankings'][i]\n",
    "    picture_names = get_image_names(i,dataA)\n",
    "    # sort picture_names according to idxs\n",
    "    picture_names = [picture_names[i] for i in idxs]\n",
    "    dataA[\"pred_rankings\"][i] = picture_names    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_image_names(69,dataA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataA[\"pred_rankings\"][69], dataA[\"expected_order\"][69]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataA['expected_order'][0],dataA['pred_rankings'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top1accuracy(pred_rankings,expected_order):\n",
    "    correct = 0\n",
    "    for i in range(len(pred_rankings)):\n",
    "        if pred_rankings[i][0] == expected_order[i][0]:\n",
    "            correct += 1\n",
    "    return correct/len(pred_rankings)\n",
    "\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "def spearman_correlation(pred_rankings,expected_order):\n",
    "    corr = []\n",
    "    for i in range(len(pred_rankings)):\n",
    "        corr.append(spearmanr(pred_rankings[i],expected_order[i]).correlation)\n",
    "    return np.mean(corr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataA_train = only_train(dataA)\n",
    "print(\"compare image captions with sentence\")\n",
    "print(\"top1 accuracy\")\n",
    "print(top1accuracy(dataA_train['pred_rankings'],dataA_train['expected_order']))\n",
    "\n",
    "print(\"spearman rank correlation\")\n",
    "print(spearman_correlation(dataA_train['pred_rankings'],dataA_train['expected_order']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## use gpt sentence/meaning (compound) embeddings to classify image captions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ziel: sortiere die 5 Bilder wie folgt\n",
    "1: literal, 2: √§hnlich wie literal, 3: √§hnlich wie idiomatic, 4: idiomatic, 5: unrelated "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataA.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_to_literal = []\n",
    "sim_to_idiomatic = []\n",
    "m = \"meanLast4\"\n",
    "\n",
    "n = 40\n",
    "\n",
    "#emb_lit = dataA[\"gpt_compound_embedding_literal_meaning_\" +m][n]\n",
    "#emb_id = dataA[\"gpt_compound_embedding_idiomatic_meaning_\" +m][n]\n",
    "\n",
    "\n",
    "emb_lit = dataA[\"gpt_literal_sentence_embedding_\" +m][n]\n",
    "emb_id = dataA[\"gpt_idiomatic_sentence_embedding_\" +m][n]\n",
    "\n",
    "\n",
    "#emb_lit = dataA[\"gpt_literal_meaning_embedding_\" +m][n]\n",
    "#emb_id = dataA[\"gpt_idiomatic_meaning_embedding_\" +m][n]\n",
    "\n",
    "for i in [1,2,3,4,5]:\n",
    "    emb_image = dataA[\"image\" + str(i) + \"_caption_embedding_\" + m][n]\n",
    "    sim_to_literal.append(cosine_similarity(emb_lit,emb_image))\n",
    "    sim_to_idiomatic.append(cosine_similarity(emb_id,emb_image))\n",
    "\n",
    "idx_lit = np.argsort(sim_to_literal )\n",
    "idx_id = np.argsort(sim_to_idiomatic )\n",
    "# reverse the indices\n",
    "idx_lit = idx_lit[::-1].tolist()\n",
    "idx_id = idx_id[::-1].tolist()\n",
    "\n",
    "\n",
    "name_list = get_image_names(n,dataA)\n",
    "\n",
    "name_list_lit = [name_list[j] for j in idx_lit]\n",
    "name_list_id = [name_list[j] for j in idx_id]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileDirectory = 'D:\\\\Wiebke Petersen\\\\Downloads\\\\AdMIRe Subtask A Train\\\\train'\n",
    "\n",
    "compound = dataA[\"compound\"][n]\n",
    "print(compound)\n",
    "print(\"literal\")\n",
    "print(dataA[\"gpt_literal_meaning\"][n])\n",
    "for fn in name_list_lit:\n",
    "    display_image(compound,fn)\n",
    "\n",
    "print(\"idiomatic\")\n",
    "print(dataA[\"gpt_idiomatic_meaning\"][n])\n",
    "for fn in name_list_id:\n",
    "    display_image(compound,fn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataA[\"expected_order\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare all pictures to each other and get 2 pairs of most similar ones.\n",
    "\n",
    "#m=\"meanLast4\"\n",
    "m= \"lastCLS\"\n",
    "n= 45\n",
    "\n",
    "dataA[\"pairs\"] = [None for p in range(len(dataA))]\n",
    "\n",
    "for n in range(len(dataA)):\n",
    "    sim = np.zeros((5,5))\n",
    "\n",
    "    for i in range(5):\n",
    "        emb_image_i = dataA[\"image\" + str(i+1) + \"_caption_embedding_\" + m][n]\n",
    "        for j in range(i+1,5):\n",
    "            emb_image_j = dataA[\"image\" + str(j+1) + \"_caption_embedding_\" + m][n]\n",
    "            sim[i,j] = cosine_similarity(emb_image_i,emb_image_j)\n",
    "        \n",
    "       \n",
    "    name_list = get_image_names(n,dataA)\n",
    "    compound = dataA[\"compound\"][n]\n",
    "    \n",
    "    u,v = np.unravel_index(np.argmax(sim),sim.shape) # indices of pair with highest similarity \n",
    "    simN = np.delete(sim,[u,v],0)\n",
    "    simN = np.delete(simN,[u,v],1)\n",
    "    max = np.max(simN)\n",
    "    b = np.where(sim == max)\n",
    "    u1 = b[0][0] # u1,v1 indices of pair with second highest similarity \n",
    "    v1 = b[1][0]\n",
    "\n",
    "    unrel = list(set([0,1,2,3,4])-set([u,v,u1,v1]))[0]\n",
    "    dataA[\"pairs\"][n] = [[(v+1,u+1),(v1+1,u1+1),unrel+1],[(name_list[v],name_list[u]),(name_list[v1],name_list[u1]),name_list[unrel]]]\n",
    "\n",
    "\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataA[\"pairs\"][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataA[\"literal_image\"] = [None for p in range(len(dataA))]\n",
    "dataA[\"idiomatic_image\"] = [None for p in range(len(dataA))]\n",
    "dataA[\"unrelated_image\"] = [None for p in range(len(dataA))]\n",
    "\n",
    "m = \"meanLast4\"\n",
    "for n in range(len(dataA)):\n",
    "    [(u1,v1),(u2,v2),un] = dataA[\"pairs\"][n][0]\n",
    "    # compare to gpt_sentence_embedding\n",
    "    comp_lit = dataA[\"gpt_literal_meaning_embedding_\" + m][n]\n",
    "    comp_id = dataA[\"gpt_idiomatic_meaning_embedding_\" + m][n]\n",
    "    lit_sim11 = cosine_similarity(dataA[\"image\"+str(u1)+\"_caption_embedding_\"+ m][n], comp_lit)\n",
    "    lit_sim12 = cosine_similarity(dataA[\"image\"+str(v1)+\"_caption_embedding_\"+ m][n], comp_lit)\n",
    "    lit_sim21 = cosine_similarity(dataA[\"image\"+str(u2)+\"_caption_embedding_\"+ m][n], comp_lit)\n",
    "    lit_sim22 = cosine_similarity(dataA[\"image\"+str(v2)+\"_caption_embedding_\"+ m][n], comp_lit)\n",
    "    id_sim11 = cosine_similarity(dataA[\"image\"+str(u1)+\"_caption_embedding_\"+ m][n], comp_id)\n",
    "    id_sim12 = cosine_similarity(dataA[\"image\"+str(v1)+\"_caption_embedding_\"+ m][n], comp_id)\n",
    "    id_sim21 = cosine_similarity(dataA[\"image\"+str(u2)+\"_caption_embedding_\"+ m][n], comp_id)\n",
    "    id_sim22 = cosine_similarity(dataA[\"image\"+str(v2)+\"_caption_embedding_\"+ m][n], comp_id)\n",
    "    if np.max([lit_sim11,  lit_sim12]) > np.max([lit_sim21 , lit_sim22]):\n",
    "        if lit_sim11 > lit_sim12:\n",
    "            dataA[\"literal_image\"][n] = (u1,v1)\n",
    "        else:\n",
    "            dataA[\"literal_image\"][n] = (v1,u1)\n",
    "        if id_sim21 > id_sim22:\n",
    "            dataA[\"idiomatic_image\"][n] = (u2,v2)\n",
    "        else: \n",
    "            dataA[\"idiomatic_image\"][n] = (v2,u2)\n",
    "    else:\n",
    "        if lit_sim21 > lit_sim22:\n",
    "            dataA[\"literal_image\"][n] = (u2,v2)\n",
    "        else:\n",
    "            dataA[\"literal_image\"][n] = (v2,u2)\n",
    "        if id_sim11 > id_sim12:\n",
    "            dataA[\"idiomatic_image\"][n] = (u1,v1)\n",
    "        else:\n",
    "            dataA[\"idiomatic_image\"][n] = (v1,u1)\n",
    "    dataA[\"unrelated_image\"][n] = un  \n",
    "\n",
    "\n",
    "            \n",
    "    \n",
    "    \n",
    "    \n",
    "     \n",
    "                                 \n",
    "                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataA[\"pred_rankings_combined\"] = [0 for p in range(len(dataA))]\n",
    "\n",
    "for n in range(len(dataA)):\n",
    "    if dataA[\"pred_sentence_and_sentence_meanLast4\"][n] == \"literal\":\n",
    "        pred_idx = [dataA[\"literal_image\"][n][0],\n",
    "                    dataA[\"literal_image\"][n][1],\n",
    "                    dataA[\"idiomatic_image\"][n][1],\n",
    "                    dataA[\"idiomatic_image\"][n][0],\n",
    "                    dataA[\"unrelated_image\"][n]]\n",
    "    else:\n",
    "        pred_idx = [dataA[\"idiomatic_image\"][n][0],\n",
    "                    dataA[\"idiomatic_image\"][n][1],\n",
    "                    dataA[\"literal_image\"][n][1],\n",
    "                    dataA[\"literal_image\"][n][0],\n",
    "                    dataA[\"unrelated_image\"][n]]\n",
    "    names = get_image_names(n,dataA)\n",
    "    preds = [names[i-1] for i in pred_idx]\n",
    "    dataA[\"pred_rankings_combined\"][n] = preds\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataA[\"pred_rankings_combined\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataA_train = only_train(dataA)\n",
    "\n",
    "print(\"combined approach idiomaticity + image caption analysis\")\n",
    "print(\"top1 accuracy\")\n",
    "print(top1accuracy(dataA_train['pred_rankings_combined'],dataA_train['expected_order']))\n",
    "\n",
    "print(\"spearman rank correlation\")\n",
    "print(spearman_correlation(dataA_train['pred_rankings_combined'],dataA_train['expected_order']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def find_permutation(L1, L2):\n",
    "    oneline = []\n",
    "    for n in L1:\n",
    "        # Look for n in L2.\n",
    "        # Sage's one-line permutation format expects indices to start at 1, not 0,\n",
    "        # so add 1 to all indices here.\n",
    "        j = L2.index(n) + 1\n",
    "        # If we've already found this instance, look in the rest of the list for another one.\n",
    "        while j in oneline:\n",
    "            j += L2[j:].index(n) + 1\n",
    "        oneline.append(j)\n",
    "    return oneline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataA_train = only_train(dataA)\n",
    "\n",
    "lit_acc = 0\n",
    "id_acc = 0\n",
    "un_acc = 0\n",
    "for n in range(len(dataA_train)):\n",
    "    [lit,id,un] = dataA_train[\"pairs\"][n][0]\n",
    "    order = dataA_train[\"expected_order\"][n]\n",
    "    names = get_image_names(n,dataA_train)\n",
    "    order = find_permutation(names,order)\n",
    "#    print(order)\n",
    "    if order[4] == un:\n",
    "        un_acc = un_acc + 1\n",
    "    if dataA_train[\"sentence_type\"][n] == \"literal\":\n",
    "        order = [(order[0],order[1]),(order[3],order[2]),order[4]]\n",
    "    else:\n",
    "        order = [(order[3],order[2]),(order[1],order[0]),order[4]]\n",
    "    lit_acc = lit_acc + 1 - len(list(set(lit)-set(order[0])))/2 \n",
    "    id_acc = id_acc + 1 - len(list(set(id)-set(order[1])))/2 \n",
    "print(\"accuracy on unrelated: \", un_acc/len(dataA_train))\n",
    "print(\"accuracy on literal: \", lit_acc/len(dataA_train))\n",
    "print(\"accuracy on idiomatic: \", id_acc/len(dataA_train))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save dataA pickle\n",
    "import pickle\n",
    "dataA.to_pickle(\"dataA.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in pickle file dataA.pkl\n",
    "\n",
    "dataA = pd.read_pickle('dataA.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataA.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mehr in Funktionen packen. \n",
    "Bei Captions nur 2 S√§tze betrachten.\n",
    "Weg √ºber idiomatic/literal und dann erst Bilder ausw√§hlen. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## chatgpt image descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gpt_image = pd.read_csv(\"gpt_image_descriptions_all.csv\", sep=',')\n",
    "# gpt data needs some cleanup:\n",
    "# replace ‚Äô with ' in all columns\n",
    "for column in data_gpt_image.columns:\n",
    "    data_gpt_image[column] = data_gpt_image[column].str.replace(\"‚Äô\",\"'\")\n",
    "\n",
    "\n",
    "\n",
    "merged_df = pd.merge(dataA, data_gpt_image, on='compound')\n",
    "dataA = merged_df \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentence embeddings \n",
    "\n",
    "types = [\"literal_image\",\"idiomatic_image\"]\n",
    "\n",
    "\n",
    "for t in types:\n",
    "    # tokenize the column\n",
    "    tokenized = tokenize(dataA[\"gpt_\" + t].tolist())\n",
    "\n",
    "    # hidden states for gpt_Meaning\n",
    "    input_ids = torch.tensor(tokenized[\"input_ids\"]).to(device)\n",
    "    attention_mask = torch.tensor(tokenized[\"attention_mask\"]).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids, attention_mask)\n",
    "\n",
    "    hidden_states = output.hidden_states\n",
    "\n",
    "    # add a columns to data_chatGPT with the embeddings of the gpt_sentence for each method in methods\n",
    "    for method in methods:\n",
    "        X = get_sentence_embedding(hidden_states,method)\n",
    "        X = np.array([x.cpu().numpy() for x in X]).tolist()\n",
    "        dataA[\"gpt_\"+ t + \"_embedding_\"+ method] = X\n",
    "    # add gpt_compound_embeddings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataA.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zweistufig: (a) +/- idiomatic, (b) compare picture captions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
