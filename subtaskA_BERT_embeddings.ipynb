{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computes BERT embeddings \n",
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read tsv file\n",
    "import csv\n",
    "import sys\n",
    "import ast\n",
    "\n",
    "import pandas as pd\n",
    "dataDirectory = \"./data/\"\n",
    "\n",
    "# read in competition data\n",
    "dataA_train = pd.read_csv(dataDirectory + \"subtask_a_train.tsv\", sep='\\t')\n",
    "dataA_train['expected_order'] = dataA_train['expected_order'].apply(ast.literal_eval)\n",
    "dataA_dev = pd.read_csv(dataDirectory + \"subtask_a_dev.tsv\", sep='\\t')\n",
    "dataA_test = pd.read_csv(dataDirectory +\"subtask_a_test.tsv\", sep='\\t')\n",
    "\n",
    "dataA = pd.concat([dataA_train,dataA_dev,dataA_test])\n",
    "# reset index\n",
    "dataA = dataA.reset_index(drop=True)\n",
    "\n",
    "# read in chatGPT data from csv\n",
    "data_chatGPT_train = pd.read_csv(dataDirectory + \"chatGPTNew_train.csv\")\n",
    "data_chatGPT_dev = pd.read_csv(dataDirectory + \"chatGPTNew_dev.csv\")\n",
    "data_chatGPT_test = pd.read_csv(dataDirectory + \"chatGPTNew_test.csv\")\n",
    "data_chatGPT = pd.concat([data_chatGPT_train,data_chatGPT_dev,data_chatGPT_test])\n",
    "\n",
    "data_chatGPT = data_chatGPT.reset_index(drop=True)\n",
    "\n",
    "# rename each column with \"gpt_\" in front of the column name\n",
    "data_chatGPT.rename(columns=lambda x: 'gpt_' + x, inplace=True)\n",
    "\n",
    "# inserting the missing compound column\n",
    "data_chatGPT[\"compound\"] = [None for i in range(len(data_chatGPT))]\n",
    "for i in range(len(data_chatGPT)):\n",
    "    data_chatGPT[\"compound\"][i] = data_chatGPT[\"gpt_idiomatic_meaning\"][i].split(\" is\")[0].strip().lower()\n",
    "\n",
    "# read in gpt image description data\n",
    "data_gpt_image = pd.read_csv(dataDirectory  + \"gpt_image_descriptions_all.csv\", sep=',')\n",
    "\n",
    "# merge data into one dataframe\n",
    "dataA = pd.merge(dataA, data_chatGPT, on='compound')\n",
    "dataA = pd.merge(dataA, data_gpt_image, on='compound')\n",
    "\n",
    "# cleanup data\n",
    "# replace ’ with ' in all columns\n",
    "for column in dataA.columns:\n",
    "    dataA[column] = dataA[column].str.replace(\"’\",\"'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if not data_gpt_image.shape[1] + data_chatGPT.shape[1] + dataA_train.shape[1] - 2 == dataA.shape[1]:\n",
    "    print(\"There is a problem with the merged file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns the dataframe sample and train (data items that have literal/idiomatic information given)\n",
    "def only_train(dataA): # returns the dataframe sample and train (data items that have literal/idiomatic information given)\n",
    "    return pd.concat([dataA[dataA[\"subset\"] == \"Sample\"],dataA[dataA[\"subset\"]== \"Train\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing of text (from Victoria)\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "def prepare_text(raw_text):\n",
    "    \n",
    "    # Convert text to lowercase and remove punctuation\n",
    "    normalized_text = raw_text.lower()\n",
    "    normalized_text = re.sub(r\"[^a-zA-Z\\s]\", \"\", normalized_text)\n",
    "\n",
    "    # Tokenize the normalized text\n",
    "    tokens = word_tokenize(normalized_text)\n",
    "\n",
    "    # Apply POS tagging and retain only nouns, verbs\n",
    "    pos_tags = nltk.pos_tag(tokens, tagset='universal')\n",
    "    pos_tags_to_keep = {\"NOUN\", \"VERB\"}\n",
    "    filtered_tokens = [word for word, pos in pos_tags if pos in pos_tags_to_keep]\n",
    "\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_text = [word for word in filtered_tokens if word.lower() not in stop_words]\n",
    "\n",
    "    # Lemmatize the remaining tokens\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_text = [lemmatizer.lemmatize(word) for word in filtered_text]\n",
    "    \n",
    "    return \" \".join(lemmatized_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed = False\n",
    "#preprocessed = True\n",
    "\n",
    "if preprocessed == True:\n",
    "    dataA[\"sentence\"] = dataA[\"sentence\"].apply(prepare_text) \n",
    "    dataA[\"compound\"] = dataA[\"compound\"].apply(prepare_text)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idea: we use a pretrained BERT model to generate embeddings of sentences and of the compound in the context of the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "from transformers import AutoModel\n",
    "\n",
    "# model is selected from https://huggingface.co/models\n",
    "checkpoint = 'bert-base-uncased' \n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = AutoModel.from_pretrained(checkpoint, output_hidden_states=True).to(device)\n",
    "model = model.eval()\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch, padding=True, truncation=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Computing sentence-based embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# different pooling methods for embeddings are computed\n",
    "# NOTE: padding tokens should be excluded (not done yet)\n",
    "\n",
    "def get_sentence_embedding(hidden_states,method):\n",
    "    sentence_embedding = []\n",
    "    if method == 'meanLast4': # average of all tokens of the last 4 layers\n",
    "        for i in range(len(hidden_states[0])):\n",
    "            # token_vecs is mean of last 4 layers\n",
    "            token_tensor = torch.stack([hidden_states[-1][i], hidden_states[-2][i], hidden_states[-3][i], hidden_states[-4][i]], dim=0)\n",
    "            token_vecs = torch.mean(token_tensor, dim=0)\n",
    "            sentence_embedding.append(torch.mean(token_vecs, dim=0))\n",
    "    elif method == 'meanSecondToLast': # average of second to last layer\n",
    "        for i in range(len(hidden_states[-2])):\n",
    "            token_vecs = hidden_states[-2][i]\n",
    "            sentence_embedding.append(torch.mean(token_vecs, dim=0))\n",
    "    elif method == 'meanLast': # average of last layer\n",
    "        for i in range(len(hidden_states[-1])):\n",
    "            token_vecs = hidden_states[-1][i]\n",
    "            sentence_embedding.append(torch.mean(token_vecs, dim=0))\n",
    "    elif method == 'lastCLS': # CLS token of last layer\n",
    "        sentence_embedding = hidden_states[-1][:, 0, :]\n",
    "    elif method == 'meanFirst': # average of first layer\n",
    "        for i in range(len(hidden_states[0])):\n",
    "            token_vecs = hidden_states[0][i]\n",
    "            sentence_embedding.append(torch.mean(token_vecs, dim=0))\n",
    "    elif method == 'firstCLS': # CLS token of first layer\n",
    "        sentence_embedding = hidden_states[0][:, 0, :]\n",
    "    return sentence_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence\n",
      "image1_caption\n",
      "image2_caption\n",
      "image3_caption\n",
      "image4_caption\n",
      "image5_caption\n",
      "gpt_idiomatic_meaning\n",
      "gpt_literal_meaning\n",
      "gpt_idiomatic_sentence\n",
      "gpt_literal_sentence\n",
      "gpt_idiomatic_image\n",
      "gpt_literal_image\n"
     ]
    }
   ],
   "source": [
    "sentence_type_columns = ['sentence', \n",
    "                         'image1_caption', 'image2_caption', 'image3_caption', 'image4_caption', 'image5_caption', \n",
    "                         'gpt_idiomatic_meaning', 'gpt_literal_meaning', \n",
    "                         'gpt_idiomatic_sentence', 'gpt_literal_sentence',\n",
    "                         'gpt_idiomatic_image', 'gpt_literal_image']\n",
    "\n",
    "methods = ['meanSecondToLast','meanLast4','meanLast','meanFirst','firstCLS','lastCLS']\n",
    "\n",
    "for column in sentence_type_columns:\n",
    "    print(column)\n",
    "    dataA_sentence_tokenized = tokenize(dataA[column].tolist())\n",
    "    \n",
    "    # convert input_ids to tensor\n",
    "    input_ids_sentence = torch.tensor(dataA_sentence_tokenized[\"input_ids\"]).to(device)\n",
    "    attention_mask_sentence = torch.tensor(dataA_sentence_tokenized[\"attention_mask\"]).to(device)\n",
    "\n",
    "    # pass input_ids to model\n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids_sentence, attention_mask_sentence)\n",
    "    \n",
    "    hidden_states_sentence = output.hidden_states\n",
    "\n",
    "    # use all methods for getting sentence embeddings and add them to dataA\n",
    "\n",
    "\n",
    "    for method in methods:\n",
    "        X = get_sentence_embedding(hidden_states_sentence,method)\n",
    "        X = np.array([x.cpu().numpy() for x in X]).tolist()\n",
    "        # add a new column to dataA \n",
    "        dataA[column + '_embedding_'+ method] = X\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers: 13   (including initial embeddings)\n",
      "Number of batches: 100\n",
      "Number of tokens: 30\n",
      "Number of hidden units: 768\n"
     ]
    }
   ],
   "source": [
    "print (\"Number of layers:\", len(hidden_states_sentence), \"  (including initial embeddings)\")\n",
    "layer_i = 0\n",
    "print (\"Number of batches:\", len(hidden_states_sentence[layer_i]))\n",
    "batch_i = 0\n",
    "print (\"Number of tokens:\", len(hidden_states_sentence[layer_i][batch_i]))\n",
    "token_i = 0\n",
    "print (\"Number of hidden units:\", len(hidden_states_sentence[layer_i][batch_i][token_i]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing compound-based embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes the compound occurs in the sentence only in plural form. So both forms are needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "##!pip install inflect\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wiebke Petersen\\AppData\\Local\\Temp\\ipykernel_28496\\351273696.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataA[\"compound_plural\"][i] = engine.plural(dataA[\"compound\"][i])\n"
     ]
    }
   ],
   "source": [
    "# sometimes the compound occurs in plural form in the sentence\n",
    "\n",
    "# add a new column to dataA with the plural form of the compound \n",
    "\n",
    "\n",
    "from re import *\n",
    "import inflect\n",
    "\n",
    "engine = inflect.engine()\n",
    "\n",
    "dataA[\"compound_plural\"] = [None for i in range(len(dataA))]\n",
    "\n",
    "for i in range(len(dataA[\"compound\"])):\n",
    "    dataA[\"compound_plural\"][i] = engine.plural(dataA[\"compound\"][i])\n",
    "\n",
    "# tokenize all compounds (original and plural)\n",
    "dataA_compound_tokenized = tokenize(dataA[\"compound\"].tolist())\n",
    "dataA_compound_plural_tokenized = tokenize(dataA[\"compound_plural\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns the index of the compound in the sentence\n",
    "def get_idx(compound_tokens, compound_plural_tokens, sentence_tokens):\n",
    "    # remove 0-tokens from compound_tokens (removes tokens that are due to padding)\n",
    "    compound_tokens = [i for i in compound_tokens if i != 0]\n",
    "    # remove [CLS] and [SEP] from compound_tokens\n",
    "    compound_tokens = compound_tokens[1:-1]\n",
    "    compound_plural_tokens = [i for i in compound_plural_tokens if i != 0]\n",
    "    compound_plural_tokens = compound_plural_tokens[1:-1]\n",
    "    idx = []\n",
    "    # find the first occurence of the sequence of compound_tokens in sentence_tokens (singular and plural forms)\n",
    "    for i in range(len(sentence_tokens)):\n",
    "        if sentence_tokens[i:i+len(compound_tokens)] == compound_tokens:\n",
    "            for j in range(i, i+ len(compound_tokens)):\n",
    "                idx.append(j)\n",
    "    for i in range(len(sentence_tokens)):\n",
    "        if sentence_tokens[i:i+len(compound_plural_tokens)] == compound_plural_tokens:\n",
    "            for j in range(i, i+ len(compound_plural_tokens)):\n",
    "                idx.append(j)\n",
    "    # remove duplicates from idx\n",
    "    idx = list(set(idx))\n",
    "    return idx\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 5, 6, 7]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testen\n",
    "get_idx([99,1,5,100,0,0],[99,1,5,2,100,0,0],[1,5,3,7,4,1,5,2,1,9,0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns the embeddings of the tokens in idxList. \n",
    "# The embeddings are combined to a single embedding by different averaging methods\n",
    "import numpy as np\n",
    "def get_idxList_embedding(hidden_states,idxLists,method):\n",
    "    embedding = []\n",
    "    if method == 'meanLast4':\n",
    "        for i in range(len(hidden_states[-1])):\n",
    "            # token_vecs is mean of last 4 layers\n",
    "            idxList = idxLists[i]\n",
    "            token_tensor = torch.stack([hidden_states[-1][i][idxList], hidden_states[-2][i][idxList], hidden_states[-3][i][idxList], hidden_states[-4][i][idxList]], dim=0)\n",
    "            token_vecs = torch.mean(token_tensor, dim=0)\n",
    "            embedding.append(torch.mean(token_vecs, dim=0).tolist())\n",
    "    elif method == 'meanSecondToLast':\n",
    "        for i in range(len(hidden_states[-2])):\n",
    "            idxList = idxLists[i]\n",
    "            token_vecs = hidden_states[-2][i][idxList]\n",
    "            embedding.append(torch.mean(token_vecs, dim=0).tolist())\n",
    "    elif method == 'meanLast':\n",
    "        for i in range(len(hidden_states[-1])):\n",
    "            idxList = idxLists[i]\n",
    "            token_vecs = hidden_states[-1][i][idxList]\n",
    "            embedding.append(torch.mean(token_vecs, dim=0).tolist())\n",
    "    elif method == 'meanFirst':\n",
    "        for i in range(len(hidden_states[0])):\n",
    "            idxList = idxLists[i]\n",
    "            token_vecs = hidden_states[0][i][idxList]\n",
    "            embedding.append(torch.mean(token_vecs, dim=0).tolist())\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentence embeddings \n",
    "sentence_type_columns = ['sentence', \n",
    "#                         'image1_caption', 'image2_caption', 'image3_caption', 'image4_caption', 'image5_caption', \n",
    "                         'gpt_idiomatic_meaning', 'gpt_literal_meaning', \n",
    "                         'gpt_idiomatic_sentence', 'gpt_literal_sentence',\n",
    "#                         'gpt_idiomatic_image', 'gpt_literal_image'\n",
    "                         ]\n",
    "\n",
    "compound_methods = ['meanSecondToLast','meanLast4','meanLast','meanFirst']\n",
    "\n",
    "compound_tokenized = tokenize(dataA[\"compound\"].tolist())\n",
    "compound_plural_tokenized = tokenize(dataA[\"compound_plural\"].tolist())    \n",
    "\n",
    "for column in sentence_type_columns:\n",
    "    # tokenize the column\n",
    "    tokenized = tokenize(dataA[column].tolist())\n",
    "\n",
    "    # hidden states for gpt_Meaning\n",
    "    input_ids = torch.tensor(tokenized[\"input_ids\"]).to(device)\n",
    "    attention_mask = torch.tensor(tokenized[\"attention_mask\"]).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids, attention_mask)\n",
    "\n",
    "    hidden_states = output.hidden_states\n",
    " \n",
    "    # add gpt_compound_embeddings\n",
    " \n",
    "    # add column to dataA with the indices of the compound in the sentence\n",
    "    dataA[column + \"_compound_idx\"] = [get_idx(compound_tokenized[\"input_ids\"][i], \n",
    "                                               compound_plural_tokenized[\"input_ids\"][i], \n",
    "                                               tokenized[\"input_ids\"][i]) for i in range(len(dataA))]\n",
    "    \n",
    "    # apply the methods in compound_methods to get the embeddings of the compound\n",
    "    for method in compound_methods:\n",
    "        dataA['compound_embedding_'+ column + \"_\"+ method] = get_idxList_embedding(hidden_states,\n",
    "                                                                                  dataA[column + \"_compound_idx\"],\n",
    "                                                                                  method) \n",
    "    dataA = dataA.copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt_literal_sentence\n",
      "donkey work\n",
      "The donkey's work in the field involved pulling heavy carts all day.\n",
      "25\n",
      "gpt_literal_sentence\n",
      "loan shark\n",
      "The aquarium exhibit featured a model of a shark alongside facts about marine life.\n",
      "50\n",
      "gpt_literal_sentence\n",
      "peas in a pod\n",
      "The peas in the pod were perfectly round and green, ready for harvest.\n",
      "91\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[-0.012345743365585804, -0.13739410042762756, 0.04319131001830101]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print  if compound_idx is empty (ideally there should be no empty compound_idx)\n",
    "for column in sentence_type_columns:\n",
    "    for i in range(len(dataA)):\n",
    "        if len(dataA[column + \"_compound_idx\"][i]) == 0:\n",
    "            print(column)\n",
    "            print(dataA[\"compound\"][i])\n",
    "            print(dataA[column][i])\n",
    "            print(i)\n",
    "            \n",
    "dataA[\"compound_embedding_gpt_literal_sentence_meanLast\"][91][:3]\n",
    "# if idx = [] then embedding = nan's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wiebke Petersen\\AppData\\Local\\Temp\\ipykernel_28496\\1725364793.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataA['compound_embedding_'+ column + \"_\"+ method][i] = dataA[column + \"_embedding_\"+ method][i]\n"
     ]
    }
   ],
   "source": [
    "# replace nan-embeddings (due to missing compound) by corresponding sentence embedding:\n",
    "for method in compound_methods:\n",
    "    for i in range(len(dataA)):\n",
    "        if len(dataA[column + \"_compound_idx\"][i]) == 0:\n",
    "            dataA['compound_embedding_'+ column + \"_\"+ method][i] = dataA[column + \"_embedding_\"+ method][i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writes all column names in a file for later reference\n",
    "with open('column.txt', 'w') as f:\n",
    "    for c in dataA.columns:\n",
    "        print(c,  file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save dataA pickle\n",
    "import pickle\n",
    "if preprocessed == True:\n",
    "    prep = \"_preprocessed_\"\n",
    "else:\n",
    "    prep = \"_\"\n",
    "dataA.to_pickle(\"dataA\"+ prep + checkpoint + \".pkl\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
