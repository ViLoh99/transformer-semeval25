{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "approaching subtask A using sentence embeddings\n",
    "\n",
    "- random baseline\n",
    "- ranking based on similarity of sentence embeddings for the compound / sentence and image captions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** needs binar_pred.pkl file generated in subtaskA_predictions_fromBERT.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read tsv file\n",
    "import csv\n",
    "import sys\n",
    "import ast\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "dataDirectory = \"./data/\"\n",
    "\n",
    "# read in competition data\n",
    "dataA_train = pd.read_csv(dataDirectory + \"subtask_a_train.tsv\", sep='\\t')\n",
    "dataA_train['expected_order'] = dataA_train['expected_order'].apply(ast.literal_eval)\n",
    "dataA_dev = pd.read_csv(dataDirectory + \"subtask_a_dev.tsv\", sep='\\t')\n",
    "dataA_xe = pd.read_csv(dataDirectory + \"subtask_a_xe.tsv\", sep='\\t')\n",
    "dataA_test = pd.read_csv(dataDirectory +\"subtask_a_test.tsv\", sep='\\t')\n",
    "\n",
    "dataA = pd.concat([dataA_train,dataA_dev,dataA_test,dataA_xe])\n",
    "# reset index\n",
    "dataA = dataA.reset_index(drop=True)\n",
    "\n",
    "# read in chatGPT data from csv\n",
    "data_chatGPT_train = pd.read_csv(dataDirectory + \"chatGPTNew_train.csv\")\n",
    "data_chatGPT_dev = pd.read_csv(dataDirectory + \"chatGPTNew_dev.csv\")\n",
    "data_chatGPT_test = pd.read_csv(dataDirectory + \"chatGPTNew_test.csv\")\n",
    "data_chatGPT = pd.concat([data_chatGPT_train,data_chatGPT_dev,data_chatGPT_test])\n",
    "\n",
    "data_chatGPT = data_chatGPT.reset_index(drop=True)\n",
    "\n",
    "# rename each column with \"gpt_\" in front of the column name\n",
    "data_chatGPT.rename(columns=lambda x: 'gpt_' + x, inplace=True)\n",
    "\n",
    "# inserting the missing compound column\n",
    "data_chatGPT[\"compound\"] = [None for i in range(len(data_chatGPT))]\n",
    "for i in range(len(data_chatGPT)):\n",
    "    data_chatGPT[\"compound\"][i] = data_chatGPT[\"gpt_idiomatic_meaning\"][i].split(\" is\")[0].strip().lower()\n",
    "\n",
    "# read in gpt image description data\n",
    "data_gpt_image = pd.read_csv(dataDirectory  + \"gpt_image_descriptions_all.csv\", sep=',')\n",
    "\n",
    "# merge data into one dataframe\n",
    "dataA = pd.merge(dataA, data_chatGPT, on='compound')\n",
    "dataA = pd.merge(dataA, data_gpt_image, on='compound')\n",
    "\n",
    "sentence_type_columns = ['sentence', \n",
    "                         'image1_caption', 'image2_caption', 'image3_caption', 'image4_caption', 'image5_caption', \n",
    "                         'gpt_idiomatic_meaning', 'gpt_literal_meaning', \n",
    "                         'gpt_idiomatic_sentence', 'gpt_literal_sentence',\n",
    "                         'gpt_idiomatic_image', 'gpt_literal_image']\n",
    "\n",
    "\n",
    "# cleanup data\n",
    "# replace ’ with ' in all columns\n",
    "for column in sentence_type_columns:\n",
    "    dataA[column] = dataA[column].str.replace(\"’\",\"'\")\n",
    "\n",
    "\n",
    "#preprocessed = False\n",
    "preprocessed = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns the dataframe sample and train (data items that have literal/idiomatic information given)\n",
    "def only_train(dataA): # returns the dataframe sample and train (data items that have literal/idiomatic information given)\n",
    "    return pd.concat([dataA[dataA[\"subset\"] == \"Sample\"],dataA[dataA[\"subset\"]== \"Train\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns the dataframe of subset\n",
    "def only_subset(dataA, subset): # returns the dataframe sample and train (data items that have literal/idiomatic information given)\n",
    "    return dataA[dataA[\"subset\"] == subset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>compound</th>\n",
       "      <th>subset</th>\n",
       "      <th>sentence_type</th>\n",
       "      <th>sentence</th>\n",
       "      <th>expected_order</th>\n",
       "      <th>image1_name</th>\n",
       "      <th>image1_caption</th>\n",
       "      <th>image2_name</th>\n",
       "      <th>image2_caption</th>\n",
       "      <th>image3_name</th>\n",
       "      <th>...</th>\n",
       "      <th>image4_name</th>\n",
       "      <th>image4_caption</th>\n",
       "      <th>image5_name</th>\n",
       "      <th>image5_caption</th>\n",
       "      <th>gpt_idiomatic_meaning</th>\n",
       "      <th>gpt_literal_meaning</th>\n",
       "      <th>gpt_idiomatic_sentence</th>\n",
       "      <th>gpt_literal_sentence</th>\n",
       "      <th>gpt_idiomatic_image</th>\n",
       "      <th>gpt_literal_image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>smoking gun</td>\n",
       "      <td>Train</td>\n",
       "      <td>idiomatic</td>\n",
       "      <td>This really is the smoking gun of a watery pas...</td>\n",
       "      <td>[57957044165.png, 22927734727.png, 30396026278...</td>\n",
       "      <td>22927734727.png</td>\n",
       "      <td>The image depicts a broken window with multipl...</td>\n",
       "      <td>30396026278.png</td>\n",
       "      <td>The image depicts a classic tobacco pipe, whic...</td>\n",
       "      <td>32526851715.png</td>\n",
       "      <td>...</td>\n",
       "      <td>57957044165.png</td>\n",
       "      <td>The image depicts a cartoon-style illustration...</td>\n",
       "      <td>58880185181.png</td>\n",
       "      <td>The image depicts a handgun resting on an oran...</td>\n",
       "      <td>Smoking gun is a metaphor for clear and undeni...</td>\n",
       "      <td>Smoking gun is a literal term for a gun that i...</td>\n",
       "      <td>The leaked emails were the smoking gun in the ...</td>\n",
       "      <td>The detective found a smoking gun at the crime...</td>\n",
       "      <td>The image depicts a crucial piece of evidence ...</td>\n",
       "      <td>The image depicts a literal gun with smoke ris...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>smoking gun</td>\n",
       "      <td>Extended Evaluation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>He had soon fired his third shot, and stood wi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>03685123161.png</td>\n",
       "      <td>The image depicts a cartoon-style illustration...</td>\n",
       "      <td>42449442342.png</td>\n",
       "      <td>The image depicts a classic tobacco pipe, whic...</td>\n",
       "      <td>42920308363.png</td>\n",
       "      <td>...</td>\n",
       "      <td>67463585344.png</td>\n",
       "      <td>The image depicts a handgun resting on an oran...</td>\n",
       "      <td>81576724950.png</td>\n",
       "      <td>The image depicts a burrito, which is a type o...</td>\n",
       "      <td>Smoking gun is a metaphor for clear and undeni...</td>\n",
       "      <td>Smoking gun is a literal term for a gun that i...</td>\n",
       "      <td>The leaked emails were the smoking gun in the ...</td>\n",
       "      <td>The detective found a smoking gun at the crime...</td>\n",
       "      <td>The image depicts a crucial piece of evidence ...</td>\n",
       "      <td>The image depicts a literal gun with smoke ris...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       compound               subset sentence_type  \\\n",
       "60  smoking gun                Train     idiomatic   \n",
       "61  smoking gun  Extended Evaluation           NaN   \n",
       "\n",
       "                                             sentence  \\\n",
       "60  This really is the smoking gun of a watery pas...   \n",
       "61  He had soon fired his third shot, and stood wi...   \n",
       "\n",
       "                                       expected_order      image1_name  \\\n",
       "60  [57957044165.png, 22927734727.png, 30396026278...  22927734727.png   \n",
       "61                                                NaN  03685123161.png   \n",
       "\n",
       "                                       image1_caption      image2_name  \\\n",
       "60  The image depicts a broken window with multipl...  30396026278.png   \n",
       "61  The image depicts a cartoon-style illustration...  42449442342.png   \n",
       "\n",
       "                                       image2_caption      image3_name  ...  \\\n",
       "60  The image depicts a classic tobacco pipe, whic...  32526851715.png  ...   \n",
       "61  The image depicts a classic tobacco pipe, whic...  42920308363.png  ...   \n",
       "\n",
       "        image4_name                                     image4_caption  \\\n",
       "60  57957044165.png  The image depicts a cartoon-style illustration...   \n",
       "61  67463585344.png  The image depicts a handgun resting on an oran...   \n",
       "\n",
       "        image5_name                                     image5_caption  \\\n",
       "60  58880185181.png  The image depicts a handgun resting on an oran...   \n",
       "61  81576724950.png  The image depicts a burrito, which is a type o...   \n",
       "\n",
       "                                gpt_idiomatic_meaning  \\\n",
       "60  Smoking gun is a metaphor for clear and undeni...   \n",
       "61  Smoking gun is a metaphor for clear and undeni...   \n",
       "\n",
       "                                  gpt_literal_meaning  \\\n",
       "60  Smoking gun is a literal term for a gun that i...   \n",
       "61  Smoking gun is a literal term for a gun that i...   \n",
       "\n",
       "                               gpt_idiomatic_sentence  \\\n",
       "60  The leaked emails were the smoking gun in the ...   \n",
       "61  The leaked emails were the smoking gun in the ...   \n",
       "\n",
       "                                 gpt_literal_sentence  \\\n",
       "60  The detective found a smoking gun at the crime...   \n",
       "61  The detective found a smoking gun at the crime...   \n",
       "\n",
       "                                  gpt_idiomatic_image  \\\n",
       "60  The image depicts a crucial piece of evidence ...   \n",
       "61  The image depicts a crucial piece of evidence ...   \n",
       "\n",
       "                                    gpt_literal_image  \n",
       "60  The image depicts a literal gun with smoke ris...  \n",
       "61  The image depicts a literal gun with smoke ris...  \n",
       "\n",
       "[2 rows x 21 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataA[dataA[\"compound\"]==\"smoking gun\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in predicted idiomatic/literal prediction\n",
    "# best prediction gained from BERT-embeddings\n",
    "\n",
    "dataA[\"binary_pred\"] = pd.read_pickle(\"binary_pred.pkl\")\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "dataA_train = only_train(dataA)\n",
    "accuracy_score(dataA_train[\"binary_pred\"].tolist(),dataA_train[\"sentence_type\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Wiebke\n",
      "[nltk_data]     Petersen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\Wiebke\n",
      "[nltk_data]     Petersen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to C:\\Users\\Wiebke\n",
      "[nltk_data]     Petersen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Wiebke\n",
      "[nltk_data]     Petersen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\Wiebke Petersen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "# preprocessing of text (from Victoria)\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "\n",
    "def prepare_text(raw_text):\n",
    "    \n",
    "    # Convert text to lowercase and remove punctuation\n",
    "    normalized_text = raw_text.lower()\n",
    "    normalized_text = re.sub(r\"[^a-zA-Z\\s]\", \"\", normalized_text)\n",
    "\n",
    "    # Tokenize the normalized text\n",
    "    tokens = word_tokenize(normalized_text)\n",
    "\n",
    "    # Apply POS tagging and retain only nouns, verbs\n",
    "    pos_tags = nltk.pos_tag(tokens, tagset='universal')\n",
    "    pos_tags_to_keep = {\"NOUN\", \"VERB\"}\n",
    "    filtered_tokens = [word for word, pos in pos_tags if pos in pos_tags_to_keep]\n",
    "\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_text = [word for word in filtered_tokens if word.lower() not in stop_words]\n",
    "\n",
    "    # Lemmatize the remaining tokens\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_text = [lemmatizer.lemmatize(word) for word in filtered_text]\n",
    "    \n",
    "    return \" \".join(lemmatized_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if preprocessed == True:\n",
    "    for column in sentence_type_columns:\n",
    "        dataA[column] = dataA[column].apply(prepare_text) \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to display images\n",
    "\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "fileDirectory = 'D:\\\\Wiebke Petersen\\\\Downloads\\\\AdMIRe Subtask A Train\\\\train'\n",
    "\n",
    "# Open the image file\n",
    "def display_image(compound, fn):\n",
    "    img = Image.open(fileDirectory + \"\\\\\" + compound + \"\\\\\" + fn)\n",
    "    new_size = (150, 150)  # Width, Height\n",
    "    img_resized = img.resize(new_size)  \n",
    "    # Display the image\n",
    "    display(img_resized)\n",
    "\n",
    "# returns list of image names sorted from image1 to image5\n",
    "def get_image_names(n,mydata):\n",
    "    names = []\n",
    "    for i in [1,2,3,4,5]:\n",
    "         names.append(mydata['image' + str(i) + '_name'][n])\n",
    "    return names\n",
    "\n",
    "# print information of 1 item:\n",
    "\n",
    "def print_item(n, mydata):\n",
    "    # print  'sentence_type', 'sentence'\n",
    "    compound = mydata['compound'][n]\n",
    "    print(compound)\n",
    "    print(mydata['sentence_type'][n])\n",
    "    print(mydata['sentence'][n])\n",
    "    print('---------------------------------------------------------------------')\n",
    "\n",
    "\n",
    "    # for image_names in 'expected_order' print image_captions\n",
    "    names  =  get_image_names(n,mydata)\n",
    "    expected_order = mydata['expected_order'][n]\n",
    "    print(expected_order)\n",
    "\n",
    "    for image_name in expected_order:\n",
    "        display_image(compound, image_name)\n",
    "        # get index of image_name in names\n",
    "        index = names.index(image_name) + 1\n",
    "        print(mydata['image'+str(index)+'_caption'][n])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -U sentence-transformers\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  SBert embeddings are generated  for all sentence like columns\n",
    "for type in sentence_type_columns:\n",
    "    dataA[type + \"_sbert_embedding\"] = dataA[type].apply(lambda x: model.encode(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "if preprocessed == True:\n",
    "    prep = \"_preprocessed_\"\n",
    "else:\n",
    "    prep = \"_\"\n",
    "\n",
    "dataA.to_pickle(\"dataA_sbert\"+ prep  + \".pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#preprocessed = False\n",
    "preprocessed = True\n",
    "\n",
    "if preprocessed == True:\n",
    "    prep = \"_preprocessed_\"\n",
    "else:\n",
    "    prep = \"_\"\n",
    "\n",
    "dataA = pd.read_pickle(\"dataA_sbert\"+ prep + \".pkl\")\n",
    "\n",
    "f = open('results_rankings.txt', 'a')\n",
    "f.write(\"\\n\"+ \"=====================================================================\")\n",
    "f.write(\"\\n\" + \"Ranking results\")\n",
    "if prep == \"_preprocessed_\":\n",
    "    f.write(\"\\n\" +\"preprocessed: True \" + \"noun, verb\")\n",
    "else: \n",
    "    f.write(\"\\n\" +\"preprocessed: False\")\n",
    "f.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['compound', 'subset', 'sentence_type', 'sentence', 'expected_order',\n",
       "       'image1_name', 'image1_caption', 'image2_name', 'image2_caption',\n",
       "       'image3_name', 'image3_caption', 'image4_name', 'image4_caption',\n",
       "       'image5_name', 'image5_caption', 'gpt_idiomatic_meaning',\n",
       "       'gpt_literal_meaning', 'gpt_idiomatic_sentence', 'gpt_literal_sentence',\n",
       "       'gpt_idiomatic_image', 'gpt_literal_image', 'binary_pred',\n",
       "       'sentence_sbert_embedding', 'image1_caption_sbert_embedding',\n",
       "       'image2_caption_sbert_embedding', 'image3_caption_sbert_embedding',\n",
       "       'image4_caption_sbert_embedding', 'image5_caption_sbert_embedding',\n",
       "       'gpt_idiomatic_meaning_sbert_embedding',\n",
       "       'gpt_literal_meaning_sbert_embedding',\n",
       "       'gpt_idiomatic_sentence_sbert_embedding',\n",
       "       'gpt_literal_sentence_sbert_embedding',\n",
       "       'gpt_idiomatic_image_sbert_embedding',\n",
       "       'gpt_literal_image_sbert_embedding'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataA.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generates submission file from column for subset\n",
    "from zipfile import ZipFile\n",
    "def make_submission(dataA, column, subset):\n",
    "    subset_data = only_subset(dataA,subset)\n",
    "    submission_df = pd.DataFrame()\n",
    "    submission_df[\"compound\"] = subset_data[\"compound\"]\n",
    "    submission_df[\"expected_order\"] = subset_data[column]\n",
    "    submission_df.to_csv(\"submission_EN.tsv\", sep=\"\\t\", index=False)\n",
    "    ZipFile('submission_EN.zip', 'w').write('submission_EN.tsv')\n",
    "    print(\"File zipped and saved as submission_EN.zip\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# evaluation functions for ranked orders\n",
    "def top1accuracy(pred_rankings,expected_order):\n",
    "    pred_rankings = pred_rankings.to_list()\n",
    "    expected_order = expected_order.to_list()\n",
    "    correct = 0\n",
    "    for i in range(len(pred_rankings)):\n",
    "        if pred_rankings[i][0] == expected_order[i][0]:\n",
    "            correct += 1\n",
    "    return round(correct/len(pred_rankings),3)\n",
    "\n",
    "\n",
    "def spearman_correlation(pred_rankings,expected_order):\n",
    "    pred_rankings = pred_rankings.to_list()\n",
    "    expected_order = expected_order.to_list()\n",
    "    corr = []\n",
    "    for i in range(len(pred_rankings)):\n",
    "        corr.append(spearmanr(pred_rankings[i],expected_order[i]).correlation)\n",
    "    return round(np.mean(corr),3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_scores(current, comparator):\n",
    "    # input = current line(example) & embeddings for sentence + captions\n",
    "    \n",
    "    scores = {}\n",
    "    # keys = image names\n",
    "    # values = scores\n",
    "    embeddings = [current[comparator+ \"_sbert_embedding\"], \n",
    "                 current[\"image1_caption_sbert_embedding\"],\n",
    "                 current[\"image2_caption_sbert_embedding\"],\n",
    "                 current[\"image3_caption_sbert_embedding\"],\n",
    "                 current[\"image4_caption_sbert_embedding\"],\n",
    "                 current[\"image5_caption_sbert_embedding\"]]\n",
    "\n",
    "    #embeddings = model.encode(sentences)\n",
    "    similarities = model.similarity(embeddings[0], embeddings)\n",
    "    # compares the embedding for the sentence including the compound \n",
    "    # with each of the embeddings, including itself and all the captions\n",
    "\n",
    "    # [0][x] required because similarities tensor has additional layer\n",
    "    score1 = similarities[0][1].item()\n",
    "    scores[current[\"image1_name\"]] = score1\n",
    "\n",
    "    score2 = similarities[0][2].item()\n",
    "    scores[current[\"image2_name\"]] = score2\n",
    "\n",
    "    score3 = similarities[0][3].item()\n",
    "    scores[current[\"image3_name\"]] = score3\n",
    "\n",
    "    score4 = similarities[0][4].item()\n",
    "    scores[current[\"image4_name\"]] = score4\n",
    "\n",
    "    score5 = similarities[0][5].item()\n",
    "    scores[current[\"image5_name\"]] = score5\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_images(scores):\n",
    "    ranking = []\n",
    "    # scores = dictionary containing the cos similarity scores\n",
    "    # comparing the sentence with the captions of the five images\n",
    "    # keys = image names\n",
    "    # values = scores\n",
    "\n",
    "    for i in range(5):\n",
    "        # find key which corresponds to the highest value\n",
    "        m = max(scores, key=scores.get)\n",
    "        # add the key (image name) to the ranking\n",
    "        ranking.append(m)\n",
    "        # delete the entry in the dictionary\n",
    "        del scores[m]\n",
    "\n",
    "    return ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dependent_preds(current, comparator):\n",
    "    pred = current[\"binary_pred\"]\n",
    "    return rank_images(sim_scores(current, \"gpt_\" + pred + \"_\" + comparator ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation on training data (rank images by similarity to original sentence):\n",
      "top1 accuracy 0.414\n",
      "spearman correlation 0.164\n",
      "File zipped and saved as submission_EN.zip\n"
     ]
    }
   ],
   "source": [
    "dataA[\"pred_order\"] = dataA.apply(lambda x: rank_images(sim_scores(x, \"sentence\")), axis=1)\n",
    "\n",
    "dataA_train = only_train(dataA)\n",
    "print(\"Evaluation on training data (rank images by similarity to original sentence):\")\n",
    "print(\"top1 accuracy\", top1accuracy(dataA_train[\"expected_order\"], dataA_train[\"pred_order\"]))\n",
    "print(\"spearman correlation\", spearman_correlation(dataA_train[\"expected_order\"], dataA_train[\"pred_order\"]))\n",
    "\n",
    "make_submission(dataA,\"pred_order\", \"Dev\")\n",
    "\n",
    "f = open('results_rankings.txt', 'a')\n",
    "f.write(\"\\n\" \"-------------------------------------------------\")\n",
    "f.write(\"\\n\" + \"Evaluation on training data (rank image captions by similarity to original sentence):\")\n",
    "f.write(\"\\n\" + \"top1 accuracy \" +  str(top1accuracy(dataA_train[\"expected_order\"],  dataA_train[\"pred_order\"])))\n",
    "f.write(\"\\n\" +\"spearman correlation \" + str(spearman_correlation(dataA_train[\"expected_order\"], dataA_train[\"pred_order\"])))\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Depending on binary prediction (literal/idiomatic) rank images by similarity to gpt_sentence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top1 accuracy 0.257\n",
      "spearman correlation 0.11\n",
      "\n",
      "Depending on binary prediction (literal/idiomatic) rank images by similarity to gpt_meaning\n",
      "top1 accuracy 0.386\n",
      "spearman correlation 0.183\n",
      "\n",
      "Depending on binary prediction (literal/idiomatic) rank images by similarity to gpt_image\n",
      "top1 accuracy 0.514\n",
      "spearman correlation 0.143\n"
     ]
    }
   ],
   "source": [
    "for sent_type in ['sentence', 'meaning','image']:\n",
    "    print(\"\\nDepending on binary prediction (literal/idiomatic) rank images by similarity to gpt_\" + sent_type)\n",
    "    dataA[\"pred_order_dependent\"] = dataA.apply(lambda x: dependent_preds(x,sent_type), axis=1)\n",
    "\n",
    "    dataA_train = only_train(dataA)\n",
    "    print(\"top1 accuracy\", top1accuracy(dataA_train[\"expected_order\"], dataA_train[\"pred_order_dependent\"]))\n",
    "    print(\"spearman correlation\", spearman_correlation(dataA_train[\"expected_order\"], dataA_train[\"pred_order_dependent\"]))\n",
    "    f = open('results_rankings.txt', 'a')\n",
    "    f.write(\"\\n\" \"-------------------------------------------------\")\n",
    "    f.write(\"\\n\" + \"\\nDepending on binary prediction (literal/idiomatic) rank images by similarity to gpt_\" + sent_type)\n",
    "    f.write(\"\\n\" + \"top1 accuracy \" +  str(top1accuracy(dataA_train[\"expected_order\"],  dataA_train[\"pred_order_dependent\"])))\n",
    "    f.write(\"\\n\" +\"spearman correlation \" + str(spearman_correlation(dataA_train[\"expected_order\"], dataA_train[\"pred_order_dependent\"])))\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top1 accuracy 0.514\n",
      "spearman correlation 0.143\n",
      "File zipped and saved as submission_EN.zip\n"
     ]
    }
   ],
   "source": [
    "sent_type = \"image\"\n",
    "dataA[\"pred_order_dependent\"] = dataA.apply(lambda x: dependent_preds(x,sent_type), axis=1)\n",
    "print(\"top1 accuracy\", top1accuracy(dataA_train[\"expected_order\"], dataA_train[\"pred_order_dependent\"]))\n",
    "print(\"spearman correlation\", spearman_correlation(dataA_train[\"expected_order\"], dataA_train[\"pred_order_dependent\"]))\n",
    "make_submission(dataA,\"pred_order\", \"Dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sim scores\n",
    "\n",
    "def dependent_preds_compare_pairs(current, sent_type):\n",
    "       preds = [0 for i in range(5)]\n",
    "       scores_lit = sim_scores(current, \"gpt_literal_\" + sent_type)\n",
    "       scores_id = sim_scores(current, \"gpt_idiomatic_\" + sent_type)\n",
    "       image_names = list(scores_lit.keys())\n",
    "       # get highest scoring image for literal and idiomatic\n",
    "       m_lit = max(scores_lit,key=scores_lit.get)\n",
    "       preds[0] = m_lit\n",
    "\n",
    "       del scores_id[m_lit]\n",
    "       m_id = max(scores_id, key=scores_id.get)\n",
    "       preds[3] = m_id\n",
    "    \n",
    "       m_lit_index = image_names.index(m_lit)\n",
    "       m_id_index = image_names.index(m_id)\n",
    "       scores_images_lit = sim_scores(current, \"image\" + str(m_lit_index + 1) + \"_caption\")\n",
    "       scores_images_id = sim_scores(current, \"image\" + str(m_id_index +1) + \"_caption\")\n",
    "       del scores_images_lit[m_lit]\n",
    "       del scores_images_lit[m_id]\n",
    "       del scores_images_id[m_lit]\n",
    "       del scores_images_id[m_id]\n",
    "\n",
    "       sim_max_lit = max(scores_images_lit, key=scores_images_lit.get)\n",
    "       preds[1] = sim_max_lit\n",
    "    \n",
    "       del scores_images_id[sim_max_lit]\n",
    "       sim_max_id = max(scores_images_id, key=scores_images_id.get)\n",
    "       preds[2] = sim_max_id\n",
    "       preds[4] = list(set(image_names).difference(set([m_lit,m_id,sim_max_lit,sim_max_id])))[0]\n",
    "       if not(set(preds) == set(image_names)):\n",
    "           print(\"there is some serious problem\") \n",
    "       if current[\"binary_pred\"] == \"idiomatic\":\n",
    "          preds_new = [preds[i] for i in [3,2,1,0,4]]\n",
    "          preds = preds_new\n",
    "       return preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation on training data (rank images dependent on binary classification. For order use inter-image similarity):\n",
      "top1 accuracy 0.543\n",
      "spearman correlation 0.381\n",
      "File zipped and saved as submission_EN.zip\n"
     ]
    }
   ],
   "source": [
    "dataA[\"pred_order_dependent\"] = dataA.apply(lambda x: dependent_preds_compare_pairs(x,\"image\"), axis=1)\n",
    "\n",
    "dataA_train = only_train(dataA)\n",
    "print(\"Evaluation on training data (rank images dependent on binary classification. For order use inter-image similarity):\")\n",
    "print(\"top1 accuracy\", top1accuracy(dataA_train[\"expected_order\"], dataA_train[\"pred_order_dependent\"]))\n",
    "print(\"spearman correlation\", spearman_correlation(dataA_train[\"expected_order\"], dataA_train[\"pred_order_dependent\"]))\n",
    "make_submission(dataA,\"pred_order_dependent\", \"Dev\")\n",
    "\n",
    "f = open('results_rankings.txt', 'a')\n",
    "f.write(\"\\n\" \"-------------------------------------------------\")\n",
    "f.write(\"\\n\" + \"Evaluation on training data (rank images dependent on binary classification. For order use inter-image similarity):\")\n",
    "f.write(\"\\n\" + \"top1 accuracy \" +  str(top1accuracy(dataA_train[\"expected_order\"],  dataA_train[\"pred_order_dependent\"])))\n",
    "f.write(\"\\n\" +\"spearman correlation \" + str(spearman_correlation(dataA_train[\"expected_order\"], dataA_train[\"pred_order_dependent\"])))\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sim scores\n",
    "\n",
    "def dependent_preds_no_pairs(current, sent_type):\n",
    "    preds = [0 for i in range(5)]\n",
    "    scores_lit = sim_scores(current, \"gpt_literal_\" + sent_type)\n",
    "    scores_id = sim_scores(current, \"gpt_idiomatic_\" + sent_type)\n",
    "    image_names = list(scores_lit.keys())\n",
    "    # get highest scoring image for literal and idiomatic\n",
    "    m_lit = max(scores_lit,key=scores_lit.get)\n",
    "    preds[0] = m_lit\n",
    "\n",
    "    del scores_id[m_lit]\n",
    "    m_id = max(scores_id, key=scores_id.get)\n",
    "    preds[3] = m_id\n",
    "\n",
    "    del scores_lit[m_lit]\n",
    "    del scores_lit[m_id]\n",
    "\n",
    "    m_lit_second = max(scores_lit, key=scores_lit.get)\n",
    "    preds[1] = m_lit_second\n",
    "\n",
    "    del scores_id[m_id]\n",
    "    del scores_id[m_lit_second]\n",
    "    m_id_second = max(scores_id, key=scores_id.get)\n",
    "    preds[2] = m_id_second\n",
    "    preds[4] = list(set(image_names).difference(set([m_lit,m_id,m_lit_second,m_id_second])))[0]\n",
    "    if not(set(preds) == set(image_names)):\n",
    "           print(\"there is some serious problem\") \n",
    "    if current[\"binary_pred\"] == \"idiomatic\":\n",
    "          preds_new = [preds[i] for i in [3,2,1,0,4]]\n",
    "          preds = preds_new\n",
    "    return preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation on training data (rank images dependent on binary classification. For order use similarity to gpt_image only):\n",
      "top1 accuracy 0.543\n",
      "spearman correlation 0.354\n",
      "File zipped and saved as submission_EN.zip\n"
     ]
    }
   ],
   "source": [
    "dataA[\"pred_order_dependent\"] = dataA.apply(lambda x: dependent_preds_no_pairs(x,\"image\"), axis=1)\n",
    "\n",
    "dataA_train = only_train(dataA)\n",
    "print(\"Evaluation on training data (rank images dependent on binary classification. For order use similarity to gpt_image only):\")\n",
    "print(\"top1 accuracy\", top1accuracy(dataA_train[\"expected_order\"], dataA_train[\"pred_order_dependent\"]))\n",
    "print(\"spearman correlation\", spearman_correlation(dataA_train[\"expected_order\"], dataA_train[\"pred_order_dependent\"]))\n",
    "make_submission(dataA,\"pred_order_dependent\", \"Dev\")\n",
    "\n",
    "f = open('results_rankings.txt', 'a')\n",
    "f.write(\"\\n\" \"-------------------------------------------------\")\n",
    "f.write(\"\\n\" + \"Evaluation on training data (rank images dependent on binary classification. For order use similarity to gpt_image only):\")\n",
    "f.write(\"\\n\" + \"top1 accuracy \" +  str(top1accuracy(dataA_train[\"expected_order\"],  dataA_train[\"pred_order_dependent\"])))\n",
    "f.write(\"\\n\" +\"spearman correlation \" + str(spearman_correlation(dataA_train[\"expected_order\"], dataA_train[\"pred_order_dependent\"])))\n",
    "f.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idiomatic_literal_prediction(current, sent_type):\n",
    "    sims = model.similarity(current[\"sentence_sbert_embedding\"], [current[\"gpt_idiomatic_\" + sent_type + \"_sbert_embedding\"], current[\"gpt_literal_\" + sent_type +  \"_sbert_embedding\"]])\n",
    "    sims = sims.numpy()\n",
    "    if np.argmax(sims[0]) == 0:\n",
    "        return \"idiomatic\"\n",
    "    else:\n",
    "        return \"literal\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy image 0.5428571428571428\n",
      "accuracy sentence 0.7428571428571429\n",
      "accuracy meaning 0.6285714285714286\n"
     ]
    }
   ],
   "source": [
    "f = open('results_rankings.txt', 'a')\n",
    "f.write(\"\\n\" \"-------------------------------------------------\")\n",
    "f.write(\"\\n\" + \"binary classification literal/idiomatic with SBERT embeddings:\")\n",
    "for sent_type in [\"image\", \"sentence\", \"meaning\"]:\n",
    "    dataA[\"binary_pred_sbert\"] = dataA.apply(lambda x: idiomatic_literal_prediction(x, sent_type), axis = 1)\n",
    "    dataA_train = only_train(dataA)\n",
    "    print(\"accuracy\",sent_type,accuracy_score(dataA_train[\"binary_pred_sbert\"], dataA_train[\"sentence_type\"]))\n",
    "    f.write(\"\\n\" + sent_type)\n",
    "    f.write(\"\\n\" + \"top1 accuracy \" +  str(top1accuracy(dataA_train[\"binary_pred_sbert\"],  dataA_train[\"sentence_type\"])))\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparing embeddings for captions with that of compound (not whole sentence)\n",
    "\n",
    "data = dataA\n",
    "#data = dataA[dataA[\"sentence_type\"]==\"literal\"]\n",
    "#data = dataA[dataA[\"sentence_type\"]==\"idiomatic\"]\n",
    "\n",
    "total_acc = 0\n",
    "total_spearman = 0\n",
    "\n",
    "for i in range(len(data)):\n",
    "\n",
    "    scores = sim_scores(current, sentences)\n",
    "    ranking = rank_images(scores)\n",
    "\n",
    "    exp_order = current[\"expected_order\"]\n",
    "    evaluation = evaluation_single(ranking,exp_order)\n",
    "    total_acc += evaluation[0]\n",
    "    total_spearman += evaluation[1]\n",
    "\n",
    "final_acc = total_acc / len(data)\n",
    "print(final_acc)\n",
    "final_spearman = total_spearman / len(data)\n",
    "print(final_spearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compound\n",
    "\n",
    "#  entire subtask A training data (70):\n",
    "# final_acc = 0.4\n",
    "# final_spearman = 0.16714285714285712\n",
    "\n",
    "# only literal (31):\n",
    "# final_acc = 0.8064516129032258\n",
    "# final_spearman = 0.39354838709677425\n",
    "\n",
    "# only idiomatic (39):\n",
    "# final_acc = 0.07692307692307693\n",
    "# final_spearman = -0.012820512820512832"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining \"sentence\" and \"compound\" embeddings (average)\n",
    "\n",
    "def sim_scores_combined(current, sentences):\n",
    "    # input = current line(example) & embeddings for sentence + captions\n",
    "    \n",
    "    scores = {}\n",
    "    # keys = image names\n",
    "    # values = scores\n",
    "\n",
    "    embeddings = model.encode(sentences)\n",
    "\n",
    "    # combining compound & sentence embeddings\n",
    "    sent_comp = (embeddings[0] + embeddings[1]) / 2\n",
    "\n",
    "    similarities = model.similarity(sent_comp, embeddings[2:])\n",
    "    # compares the embedding for the sentence and compound combined\n",
    "    # with each of the embeddings, including itself and all the captions\n",
    "\n",
    "    # [0][x] required because similarities tensor has additional layer\n",
    "    score1 = similarities[0][0].item()\n",
    "    scores[current[\"image1_name\"]] = score1\n",
    "\n",
    "    score2 = similarities[0][1].item()\n",
    "    scores[current[\"image2_name\"]] = score2\n",
    "\n",
    "    score3 = similarities[0][2].item()\n",
    "    scores[current[\"image3_name\"]] = score3\n",
    "\n",
    "    score4 = similarities[0][3].item()\n",
    "    scores[current[\"image4_name\"]] = score4\n",
    "\n",
    "    score5 = similarities[0][4].item()\n",
    "    scores[current[\"image5_name\"]] = score5\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparing embeddings for captions with that of compound and sentence (averaged)\n",
    "\n",
    "data = dataA\n",
    "#data = dataA[dataA[\"sentence_type\"]==\"literal\"]\n",
    "#data = dataA[dataA[\"sentence_type\"]==\"idiomatic\"]\n",
    "\n",
    "total_acc = 0\n",
    "total_spearman = 0\n",
    "\n",
    "for i in range(len(data)):\n",
    "\n",
    "    current = data.iloc[i]\n",
    "    sentences = [current[\"compound\"], \n",
    "                 current[\"sentence\"], \n",
    "                 current[\"image1_caption\"],\n",
    "                 current[\"image2_caption\"],\n",
    "                 current[\"image3_caption\"],\n",
    "                 current[\"image4_caption\"],\n",
    "                 current[\"image5_caption\"]]\n",
    "\n",
    "    scores = sim_scores_combined(current, sentences)\n",
    "    ranking = rank_images(scores)\n",
    "\n",
    "    exp_order = current[\"expected_order\"]\n",
    "    evaluation = evaluation_single(ranking,exp_order)\n",
    "    total_acc += evaluation[0]\n",
    "    total_spearman += evaluation[1]\n",
    "\n",
    "final_acc = total_acc / len(data)\n",
    "print(final_acc)\n",
    "final_spearman = total_spearman / len(data)\n",
    "print(final_spearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentence and compound combined\n",
    "\n",
    "# entire subtask A training data:\n",
    "# final_acc = 0.34285714285714286 -> worse than compound / sentence individually\n",
    "# final_spearman = 0.2271428571428571 -> better than either individually\n",
    "\n",
    "# only literal: -> worse than compound, better than sentence\n",
    "# final_acc = 0.7096774193548387 \n",
    "# final_spearman = 0.36774193548387096\n",
    "\n",
    "# only idiomatic:\n",
    "# final_acc = 0.05128205128205128 -> worse than either individually\n",
    "# final_spearman = 0.11538461538461536 -> better than compound, about as good as sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random baseline\n",
    "\n",
    "import random\n",
    "random.seed(2)\n",
    "\n",
    "data = dataA\n",
    "\n",
    "total_acc = 0\n",
    "total_spearman = 0\n",
    "\n",
    "for i in range(len(data)):\n",
    "\n",
    "    current = data.iloc[i]\n",
    "\n",
    "    ranking = []\n",
    "    images = [current[\"image1_name\"],\n",
    "              current[\"image2_name\"],\n",
    "              current[\"image3_name\"],\n",
    "              current[\"image4_name\"],\n",
    "              current[\"image5_name\"]]\n",
    "\n",
    "    for i in range(5):\n",
    "        rand_img = random.choice(images)\n",
    "        ranking.append(rand_img)\n",
    "        images.remove(rand_img)\n",
    "\n",
    "    exp_order = current[\"expected_order\"]\n",
    "    evaluation = evaluation_single(ranking,exp_order)\n",
    "    total_acc += evaluation[0]\n",
    "    total_spearman += evaluation[1]\n",
    "\n",
    "final_acc = total_acc / len(data)\n",
    "print(final_acc)\n",
    "final_spearman = total_spearman / len(data)\n",
    "print(final_spearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random\n",
    "\n",
    "# final_acc = 0.17142857142857143\n",
    "# final_spearman = 0.03428571428571425"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
